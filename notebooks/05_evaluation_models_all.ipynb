{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b975a1f-7f4f-490e-bb61-d806e777d683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:52:15] INFO in config: PyTorch version 2.7.1+cu128 available.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "\n",
    "from notebook_config import DATASETS_DIR, EXPERIMENTAL_RESULTS_DIR, FILES_DIR, MODEL_CONFIGS\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from port.entity_extractor import MultiEntityExtractor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e6fdd8-dce6-4d46-848c-784ea087e7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "df = pd.read_csv(DATASETS_DIR / 'full_data_clean.csv').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef902b-932e-40fc-8c63-4576056845df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>urls</th>\n",
       "      <th>text</th>\n",
       "      <th>persons</th>\n",
       "      <th>organizations</th>\n",
       "      <th>themes</th>\n",
       "      <th>locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>381</td>\n",
       "      <td>https://arabic.cnn.com/travel/article/2022/08/...</td>\n",
       "      <td>اليابان فتحت أبوابها أمام المسافرين.. ولكن ما ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>IMMIGRATION,999;WB_2670_JOBS,999;WB_2769_JOBS_...</td>\n",
       "      <td>Japan;Taiwan;Hong Kong;Singapore;Australia;Kyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>664</td>\n",
       "      <td>https://www.cnn.com/2022/08/08/media/axios-cox...</td>\n",
       "      <td>Axios, the buzzy digital media venture founded...</td>\n",
       "      <td>Roy Schwartz;Jim Vandehei;Alex Taylor;Mike Allen</td>\n",
       "      <td>Schwartz;Schwartz;Schwartz;Schwartz;New York T...</td>\n",
       "      <td>TAX_FNCACT_CHIEF,1346;TAX_FNCACT_CHIEF,2085;UN...</td>\n",
       "      <td>Washington;New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>257</td>\n",
       "      <td>https://www.cnn.com/2022/08/03/energy/joe-bide...</td>\n",
       "      <td>Candidate Joe Biden promised in 2019 to make S...</td>\n",
       "      <td>Matt Smith;Mizuho Yawger;Jamal Khashoggi;Jim S...</td>\n",
       "      <td>Rapidan Energy Group;White House;White House;W...</td>\n",
       "      <td>GENERAL_GOVERNMENT,2297;EPU_POLICY_GOVERNMENT,...</td>\n",
       "      <td>White House;The White House;Americans;Washingt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>338</td>\n",
       "      <td>https://www.cnn.com/2022/08/02/media/alex-jone...</td>\n",
       "      <td>The parents of a child who was murdered during...</td>\n",
       "      <td>Roy Lubit;Scarlett Lewis;Avi Moshenberg;Alex J...</td>\n",
       "      <td>Cnn;Cnn;Cnn</td>\n",
       "      <td>EXTREMISM,197;EPU_CATS_MIGRATION_FEAR_FEAR,204...</td>\n",
       "      <td>Sandy Hook;Connecticut;Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>319</td>\n",
       "      <td>https://www.cnn.com/style/article/india-coutur...</td>\n",
       "      <td>What India Couture Week reveals about this yea...</td>\n",
       "      <td>Amit Aggarwal;Amit Aggarwal;Amit Aggarwal;Amit...</td>\n",
       "      <td>Cnn;Fashion Design Council Of India;United States</td>\n",
       "      <td>TAX_ETHNICITY_ASIAN,806;TAX_FNCACT_ACTOR,3616;...</td>\n",
       "      <td>India;New Delhi;Paris;United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               urls  \\\n",
       "0         381  https://arabic.cnn.com/travel/article/2022/08/...   \n",
       "1         664  https://www.cnn.com/2022/08/08/media/axios-cox...   \n",
       "2         257  https://www.cnn.com/2022/08/03/energy/joe-bide...   \n",
       "3         338  https://www.cnn.com/2022/08/02/media/alex-jone...   \n",
       "4         319  https://www.cnn.com/style/article/india-coutur...   \n",
       "\n",
       "                                                text  \\\n",
       "0  اليابان فتحت أبوابها أمام المسافرين.. ولكن ما ...   \n",
       "1  Axios, the buzzy digital media venture founded...   \n",
       "2  Candidate Joe Biden promised in 2019 to make S...   \n",
       "3  The parents of a child who was murdered during...   \n",
       "4  What India Couture Week reveals about this yea...   \n",
       "\n",
       "                                             persons  \\\n",
       "0                                                      \n",
       "1   Roy Schwartz;Jim Vandehei;Alex Taylor;Mike Allen   \n",
       "2  Matt Smith;Mizuho Yawger;Jamal Khashoggi;Jim S...   \n",
       "3  Roy Lubit;Scarlett Lewis;Avi Moshenberg;Alex J...   \n",
       "4  Amit Aggarwal;Amit Aggarwal;Amit Aggarwal;Amit...   \n",
       "\n",
       "                                       organizations  \\\n",
       "0                                                      \n",
       "1  Schwartz;Schwartz;Schwartz;Schwartz;New York T...   \n",
       "2  Rapidan Energy Group;White House;White House;W...   \n",
       "3                                        Cnn;Cnn;Cnn   \n",
       "4  Cnn;Fashion Design Council Of India;United States   \n",
       "\n",
       "                                              themes  \\\n",
       "0  IMMIGRATION,999;WB_2670_JOBS,999;WB_2769_JOBS_...   \n",
       "1  TAX_FNCACT_CHIEF,1346;TAX_FNCACT_CHIEF,2085;UN...   \n",
       "2  GENERAL_GOVERNMENT,2297;EPU_POLICY_GOVERNMENT,...   \n",
       "3  EXTREMISM,197;EPU_CATS_MIGRATION_FEAR_FEAR,204...   \n",
       "4  TAX_ETHNICITY_ASIAN,806;TAX_FNCACT_ACTOR,3616;...   \n",
       "\n",
       "                                           locations  \n",
       "0  Japan;Taiwan;Hong Kong;Singapore;Australia;Kyo...  \n",
       "1                                Washington;New York  \n",
       "2  White House;The White House;Americans;Washingt...  \n",
       "3                       Sandy Hook;Connecticut;Texas  \n",
       "4                India;New Delhi;Paris;United States  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ad0c3-e3f0-4b0a-96a6-d62e427fcad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def create_multi_entity_extractor(config):\n",
    "    \"\"\"\n",
    "    Factory function to create a MultiEntityExtractor from a configuration dictionary.\n",
    "    \n",
    "    Args:\n",
    "        config (dict): Configuration dictionary with extractor classes and parameters\n",
    "        \n",
    "    Returns:\n",
    "        MultiEntityExtractor: Configured multi-entity extractor\n",
    "    \"\"\"\n",
    "    extractor = MultiEntityExtractor()\n",
    "    \n",
    "    # Add extractors for each entity type\n",
    "    for entity_type in [\"persons\", \"organizations\", \"locations\"]:\n",
    "        if entity_type in config:\n",
    "            extractor_class = config[entity_type][\"extractor\"]\n",
    "            params = config[entity_type][\"params\"]\n",
    "            extractor.add_extractor(entity_type, extractor_class(**params))\n",
    "    \n",
    "    return extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6701dffd-8d38-4785-a5f5-074c429e79ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:52:18] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:18] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:19] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:19] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:19] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:19] INFO in preprocessing: Converted to list of size 83 in 0.0010008811950683594 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:19] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:52:20] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:20] INFO in entity_extractor: Fitting PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:23] INFO in entity_extractor: Evaluating PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:23] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.743243, 'recall': 0.348837, 'jaccard': 0.311321, 'f1': 0.47482, 'accuracy': 0.084337}}, 'personal': {'micro': {'accuracy': 0.08433734939759036, 'precision': 0.7297297297297297, 'recall': 0.34249471458773784, 'jaccard': 0.30393996247654786, 'f1': 0.46618705035971225}, 'macro': {'accuracy': 0.08433734939759036, 'precision': 0.5844807802639128, 'recall': 0.37030785231156377, 'jaccard': 0.3219647910041062, 'f1': 0.41479946754201663}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:23] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:23] INFO in preprocessing: Converted to list of size 83 in 0.0009999275207519531 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:23] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:52:23] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:23] INFO in entity_extractor: Fitting PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:26] INFO in entity_extractor: Evaluating PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:26] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.320442, 'recall': 0.236735, 'jaccard': 0.157609, 'f1': 0.2723, 'accuracy': 0.072289}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.2541436464088398, 'recall': 0.1348973607038123, 'jaccard': 0.09663865546218488, 'f1': 0.17624521072796934}, 'macro': {'accuracy': 0.0, 'precision': 0.22538726333907055, 'recall': 0.12219158017350788, 'jaccard': 0.08526831267795124, 'f1': 0.13590876994491455}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:26] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:26] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:26] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:52:26] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:26] INFO in entity_extractor: Fitting PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:29] INFO in entity_extractor: Evaluating PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:29] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.520408, 'recall': 0.333333, 'jaccard': 0.255, 'f1': 0.406375, 'accuracy': 0.277108}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.5204081632653061, 'recall': 0.09026548672566372, 'jaccard': 0.08333333333333333, 'f1': 0.15384615384615385}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.3644578313253012, 'recall': 0.1390274090101533, 'jaccard': 0.12633970567565223, 'f1': 0.1831256181287887}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:29] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:29] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:29] INFO in entity_extractor: Predicting PretrainedBertEntityExtractorPure with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:32] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:32] INFO in entity_extractor: Predicting PretrainedBertEntityExtractorPure with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:34] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:34] INFO in entity_extractor: Predicting PretrainedBertEntityExtractorPure with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  14%|█▍        | 1/7 [00:19<01:57, 19.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:52:37] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:38] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:38] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:38] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:38] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:38] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:38] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:52:38] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:38] INFO in entity_extractor: Fitting PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:52:56] INFO in entity_extractor: Evaluating PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:56] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.676364, 'recall': 0.786469, 'jaccard': 0.571429, 'f1': 0.727273, 'accuracy': 0.156627}}, 'personal': {'micro': {'accuracy': 0.14457831325301204, 'precision': 0.6473779385171791, 'recall': 0.7568710359408034, 'jaccard': 0.5359281437125748, 'f1': 0.6978557504873295}, 'macro': {'accuracy': 0.14457831325301204, 'precision': 0.5442743105934774, 'recall': 0.6441625044109285, 'jaccard': 0.484573828187467, 'f1': 0.5719969635645507}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:56] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:56] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:56] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:52:56] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:52:56] INFO in entity_extractor: Fitting PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:53:14] INFO in entity_extractor: Evaluating PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:53:14] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.314356, 'recall': 0.518367, 'jaccard': 0.243295, 'f1': 0.391371, 'accuracy': 0.060241}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.2518518518518518, 'recall': 0.2991202346041056, 'jaccard': 0.15838509316770186, 'f1': 0.27345844504021444}, 'macro': {'accuracy': 0.0, 'precision': 0.19782388255102643, 'recall': 0.21398429214694273, 'jaccard': 0.12694765682387246, 'f1': 0.1961600408846637}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:53:14] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:53:14] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:53:14] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:53:14] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:53:14] INFO in entity_extractor: Fitting PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:53:31] INFO in entity_extractor: Evaluating PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:53:31] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.475, 'recall': 0.620915, 'jaccard': 0.368217, 'f1': 0.538244, 'accuracy': 0.253012}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.475, 'recall': 0.168141592920354, 'jaccard': 0.1417910447761194, 'f1': 0.24836601307189543}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.40243832472748126, 'recall': 0.1975366491990533, 'jaccard': 0.16937101053824105, 'f1': 0.244577533308788}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:53:31] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:53:31] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:53:31] INFO in entity_extractor: Predicting PretrainedBERTEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:53:45] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:53:45] INFO in entity_extractor: Predicting PretrainedBERTEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:53:59] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:53:59] INFO in entity_extractor: Predicting PretrainedBERTEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "Testing models:  29%|██▊       | 2/7 [01:57<05:28, 65.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:54:15] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:54:16] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:54:16] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:54:17] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:17] INFO in preprocessing: Converted to list of size 83 in 0.0009603500366210938 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:17] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:17] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:54:21] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:21] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.532407, 'recall': 0.243129, 'jaccard': 0.200348, 'f1': 0.333817, 'accuracy': 0.048193}}, 'personal': {'micro': {'accuracy': 0.04819277108433735, 'precision': 0.5185185185185185, 'recall': 0.23678646934460887, 'jaccard': 0.19410745233968804, 'f1': 0.32510885341074014}, 'macro': {'accuracy': 0.04819277108433735, 'precision': 0.42114040577896, 'recall': 0.2529467390008626, 'jaccard': 0.2071732065167106, 'f1': 0.28906883940175}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:22] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:22] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:22] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:25] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:25] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.264706, 'recall': 0.183673, 'jaccard': 0.121622, 'f1': 0.216867, 'accuracy': 0.156627}}, 'personal': {'micro': {'accuracy': 0.04819277108433735, 'precision': 0.2046783625730994, 'recall': 0.10263929618768329, 'jaccard': 0.07337526205450734, 'f1': 0.13671875}, 'macro': {'accuracy': 0.04819277108433735, 'precision': 0.18141135972461273, 'recall': 0.07294698273613937, 'jaccard': 0.05688582692294133, 'f1': 0.09255229999922325}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:25] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:25] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:25] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:29] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:29] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.505495, 'recall': 0.300654, 'jaccard': 0.232323, 'f1': 0.377049, 'accuracy': 0.253012}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.5054945054945055, 'recall': 0.08141592920353982, 'jaccard': 0.07540983606557378, 'f1': 0.14024390243902438}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.3052208835341365, 'recall': 0.11860802407978323, 'jaccard': 0.10768932953367284, 'f1': 0.15415343692452124}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:29] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:29] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:29] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:32] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:32] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:35] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:35] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  43%|████▎     | 3/7 [02:21<03:05, 46.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:54:38] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:54:39] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:54:39] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:54:40] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:40] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:40] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:40] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:43] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:43] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.580645, 'recall': 0.266385, 'jaccard': 0.223404, 'f1': 0.365217, 'accuracy': 0.048193}}, 'personal': {'micro': {'accuracy': 0.04819277108433735, 'precision': 0.5668202764976958, 'recall': 0.26004228329809725, 'jaccard': 0.21693121693121692, 'f1': 0.3565217391304348}, 'macro': {'accuracy': 0.04819277108433735, 'precision': 0.4607155896312523, 'recall': 0.275590561042275, 'jaccard': 0.22920427225511342, 'f1': 0.31729628235279317}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:43] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:43] INFO in preprocessing: Converted to list of size 83 in 0.0010385513305664062 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:43] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:47] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:47] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.262857, 'recall': 0.187755, 'jaccard': 0.122995, 'f1': 0.219048, 'accuracy': 0.13253}}, 'personal': {'micro': {'accuracy': 0.024096385542168676, 'precision': 0.19318181818181818, 'recall': 0.09970674486803519, 'jaccard': 0.07039337474120083, 'f1': 0.13152804642166344}, 'macro': {'accuracy': 0.024096385542168676, 'precision': 0.18196161268450425, 'recall': 0.08425889706010188, 'jaccard': 0.06274527452396825, 'f1': 0.09944001781351178}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:47] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:47] INFO in preprocessing: Converted to list of size 83 in 0.0009980201721191406 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:47] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:51] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:51] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.391304, 'recall': 0.235294, 'jaccard': 0.172249, 'f1': 0.293878, 'accuracy': 0.228916}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.391304347826087, 'recall': 0.06371681415929203, 'jaccard': 0.057971014492753624, 'f1': 0.10958904109589042}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.25, 'recall': 0.09774023921483324, 'jaccard': 0.08697830669295475, 'f1': 0.1272841393323321}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:51] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:51] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:51] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:54] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:54] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:56] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:56] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  57%|█████▋    | 4/7 [02:41<01:48, 36.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:54:59] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:59] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:59] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:54:59] INFO in entity_extractor: Fitting SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:06] INFO in entity_extractor: Evaluating SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:06] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.948187, 'recall': 0.773784, 'jaccard': 0.742394, 'f1': 0.852154, 'accuracy': 0.337349}}, 'personal': {'micro': {'accuracy': 0.3373493975903614, 'precision': 0.9481865284974094, 'recall': 0.773784355179704, 'jaccard': 0.742393509127789, 'f1': 0.8521536670547147}, 'macro': {'accuracy': 0.3373493975903614, 'precision': 0.7486608772753351, 'recall': 0.6787692463971885, 'jaccard': 0.6427676643112691, 'f1': 0.6977423875177373}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:06] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:06] INFO in preprocessing: Converted to list of size 83 in 0.0009572505950927734 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:06] INFO in entity_extractor: Fitting SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:10] INFO in entity_extractor: Evaluating SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:10] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.896341, 'recall': 0.6, 'jaccard': 0.561069, 'f1': 0.718826, 'accuracy': 0.325301}}, 'personal': {'micro': {'accuracy': 0.08433734939759036, 'precision': 0.898936170212766, 'recall': 0.49560117302052786, 'jaccard': 0.46944444444444444, 'f1': 0.6389413988657845}, 'macro': {'accuracy': 0.08433734939759036, 'precision': 0.616829957191403, 'recall': 0.3797319146716737, 'jaccard': 0.36704091640307085, 'f1': 0.4581786280270835}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:10] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:10] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:10] INFO in entity_extractor: Fitting SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:14] INFO in entity_extractor: Evaluating SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:14] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.896, 'recall': 0.732026, 'jaccard': 0.674699, 'f1': 0.805755, 'accuracy': 0.578313}}, 'personal': {'micro': {'accuracy': 0.26506024096385544, 'precision': 0.8945147679324894, 'recall': 0.7504424778761062, 'jaccard': 0.6894308943089431, 'f1': 0.8161693936477382}, 'macro': {'accuracy': 0.26506024096385544, 'precision': 0.7831958644221316, 'recall': 0.7372409068076649, 'jaccard': 0.6695856570682188, 'f1': 0.7343099132640757}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:14] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:14] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:14] INFO in entity_extractor: Predicting SlidingWindowExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:20] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:20] INFO in entity_extractor: Predicting SlidingWindowExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:23] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:23] INFO in entity_extractor: Predicting SlidingWindowExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  71%|███████▏  | 5/7 [03:09<01:06, 33.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:55:27] INFO in spacy: Loading spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:27] INFO in spacy: Loaded spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:27] INFO in spacy: Loading spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:28] INFO in spacy: Loaded spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:28] INFO in spacy: Loading spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:28] INFO in spacy: Loaded spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:28] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:28] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:28] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:28] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:40] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:40] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.62697, 'recall': 0.756871, 'jaccard': 0.521866, 'f1': 0.685824, 'accuracy': 0.084337}}, 'personal': {'micro': {'accuracy': 0.08433734939759036, 'precision': 0.5888501742160279, 'recall': 0.7145877378435518, 'jaccard': 0.4767277856135402, 'f1': 0.6456542502387775}, 'macro': {'accuracy': 0.08433734939759036, 'precision': 0.5157301064990646, 'recall': 0.6179295506177336, 'jaccard': 0.44693449902537974, 'f1': 0.5433817253802677}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:40] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:40] INFO in preprocessing: Converted to list of size 83 in 0.0010025501251220703 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:40] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:52] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:52] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.125, 'recall': 0.204082, 'jaccard': 0.084034, 'f1': 0.155039, 'accuracy': 0.060241}}, 'personal': {'micro': {'accuracy': 0.024096385542168676, 'precision': 0.10098522167487685, 'recall': 0.12023460410557185, 'jaccard': 0.05807365439093484, 'f1': 0.10977242302543509}, 'macro': {'accuracy': 0.024096385542168676, 'precision': 0.07799792682481332, 'recall': 0.09836575740190198, 'jaccard': 0.048889636724749996, 'f1': 0.08324313924037297}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:52] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:52] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:55:52] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:04] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:04] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.373134, 'recall': 0.326797, 'jaccard': 0.21097, 'f1': 0.348432, 'accuracy': 0.168675}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.36764705882352944, 'recall': 0.08849557522123894, 'jaccard': 0.07680491551459294, 'f1': 0.1426533523537803}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.25412124689233123, 'recall': 0.10252962448214042, 'jaccard': 0.08977994647382725, 'f1': 0.13398340707439169}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:04] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:04] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:04] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:14] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:14] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:23] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:23] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  86%|████████▌ | 6/7 [04:15<00:44, 44.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:56:32] INFO in spacy: Loading spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:34] INFO in spacy: Loaded spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:34] INFO in spacy: Loading spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:36] INFO in spacy: Loaded spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:36] INFO in spacy: Loading spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:38] INFO in spacy: Loaded spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:38] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:38] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:38] INFO in preprocessing: Converted to list of size 83 in 0.0012848377227783203 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:38] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:51] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:51] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.669039, 'recall': 0.794926, 'jaccard': 0.570561, 'f1': 0.72657, 'accuracy': 0.156627}}, 'personal': {'micro': {'accuracy': 0.14457831325301204, 'precision': 0.6265486725663717, 'recall': 0.7484143763213531, 'jaccard': 0.5175438596491229, 'f1': 0.6820809248554914}, 'macro': {'accuracy': 0.14457831325301204, 'precision': 0.555386374052587, 'recall': 0.6388137032789949, 'jaccard': 0.48832941296004073, 'f1': 0.5724442150652848}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:51] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:51] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:56:51] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:03] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:03] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.114634, 'recall': 0.191837, 'jaccard': 0.077303, 'f1': 0.143511, 'accuracy': 0.096386}}, 'personal': {'micro': {'accuracy': 0.03614457831325301, 'precision': 0.09069212410501193, 'recall': 0.11143695014662756, 'jaccard': 0.05263157894736842, 'f1': 0.09999999999999999}, 'macro': {'accuracy': 0.03614457831325301, 'precision': 0.06993960642082542, 'recall': 0.09260939863349502, 'jaccard': 0.04511485215369398, 'f1': 0.07671163098594513}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:03] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:03] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:03] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:16] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:16] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.349315, 'recall': 0.333333, 'jaccard': 0.205645, 'f1': 0.341137, 'accuracy': 0.180723}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.34459459459459457, 'recall': 0.09026548672566372, 'jaccard': 0.0770392749244713, 'f1': 0.14305750350631136}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.24243163128705297, 'recall': 0.11127369165994254, 'jaccard': 0.09605239180983335, 'f1': 0.14052479741096274}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:16] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:16] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:16] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:25] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:25] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:36] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:36] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models: 100%|██████████| 7/7 [05:29<00:00, 47.01s/it]\n",
      "Testing models:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:57:47] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:47] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:48] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:48] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:48] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:48] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:48] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:57:48] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:48] INFO in entity_extractor: Fitting PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:51] INFO in entity_extractor: Evaluating PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:51] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.75, 'recall': 0.412399, 'jaccard': 0.362559, 'f1': 0.532174, 'accuracy': 0.144578}}, 'personal': {'micro': {'accuracy': 0.13253012048192772, 'precision': 0.7205882352941176, 'recall': 0.39622641509433965, 'jaccard': 0.34345794392523366, 'f1': 0.511304347826087}, 'macro': {'accuracy': 0.13253012048192772, 'precision': 0.583409829795372, 'recall': 0.4095325023035866, 'jaccard': 0.3526782454493298, 'f1': 0.44375260144218326}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:51] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:51] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:51] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:57:52] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:52] INFO in entity_extractor: Fitting PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:55] INFO in entity_extractor: Evaluating PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:55] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.327957, 'recall': 0.236434, 'jaccard': 0.159269, 'f1': 0.274775, 'accuracy': 0.084337}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.26344086021505375, 'recall': 0.14, 'jaccard': 0.10061601642710473, 'f1': 0.1828358208955224}, 'macro': {'accuracy': 0.0, 'precision': 0.22624002503520577, 'recall': 0.14691807523132824, 'jaccard': 0.1034638721385709, 'f1': 0.15917125043631067}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:55] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:55] INFO in preprocessing: Converted to list of size 83 in 0.0009772777557373047 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:55] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:57:55] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:55] INFO in entity_extractor: Fitting PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:58] INFO in entity_extractor: Evaluating PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:58] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.580357, 'recall': 0.408805, 'jaccard': 0.315534, 'f1': 0.479705, 'accuracy': 0.301205}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.5803571428571429, 'recall': 0.12104283054003724, 'jaccard': 0.1113013698630137, 'f1': 0.20030816640986132}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.45953815261044173, 'recall': 0.16604384759145407, 'jaccard': 0.14850505633330024, 'f1': 0.21906859400886444}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:58] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:58] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:57:58] INFO in entity_extractor: Predicting PretrainedBertEntityExtractorPure with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:00] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:00] INFO in entity_extractor: Predicting PretrainedBertEntityExtractorPure with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:03] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:03] INFO in entity_extractor: Predicting PretrainedBertEntityExtractorPure with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  14%|█▍        | 1/7 [00:19<01:59, 19.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:58:07] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:07] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:08] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:08] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:08] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:08] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:08] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:58:08] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:08] INFO in entity_extractor: Fitting PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:58:24] INFO in entity_extractor: Evaluating PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:24] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.637895, 'recall': 0.816712, 'jaccard': 0.558011, 'f1': 0.716312, 'accuracy': 0.180723}}, 'personal': {'micro': {'accuracy': 0.14457831325301204, 'precision': 0.608421052631579, 'recall': 0.7789757412398922, 'jaccard': 0.518850987432675, 'f1': 0.6832151300236408}, 'macro': {'accuracy': 0.14457831325301204, 'precision': 0.5410300197520906, 'recall': 0.679483735809037, 'jaccard': 0.4981405471133895, 'f1': 0.587085905942215}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:24] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:24] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:24] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:58:24] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:24] INFO in entity_extractor: Fitting PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:39] INFO in entity_extractor: Evaluating PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:39] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.33631, 'recall': 0.437984, 'jaccard': 0.234927, 'f1': 0.380471, 'accuracy': 0.060241}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.2648809523809524, 'recall': 0.2542857142857143, 'jaccard': 0.1490787269681742, 'f1': 0.2594752186588921}, 'macro': {'accuracy': 0.0, 'precision': 0.22840987660264767, 'recall': 0.22430467791913575, 'jaccard': 0.14298027254263965, 'f1': 0.21568270709206505}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:39] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:39] INFO in preprocessing: Converted to list of size 83 in 0.0010008811950683594 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:39] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:58:40] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:40] INFO in entity_extractor: Fitting PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:55] INFO in entity_extractor: Evaluating PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:55] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.567568, 'recall': 0.660377, 'jaccard': 0.439331, 'f1': 0.610465, 'accuracy': 0.277108}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.5675675675675675, 'recall': 0.19553072625698323, 'jaccard': 0.17017828200972449, 'f1': 0.29085872576177285}, 'macro': {'accuracy': 0.0, 'precision': 0.4788152610441767, 'recall': 0.22243288304572073, 'jaccard': 0.1852579483473237, 'f1': 0.27772349596379997}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:55] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:55] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:58:55] INFO in entity_extractor: Predicting PretrainedBERTEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:59:10] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:10] INFO in entity_extractor: Predicting PretrainedBERTEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:59:24] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:24] INFO in entity_extractor: Predicting PretrainedBERTEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "Testing models:  29%|██▊       | 2/7 [01:52<05:12, 62.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:59:39] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:59:40] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:59:40] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-04 23:59:41] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:41] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:41] INFO in preprocessing: Converted to list of size 83 in 0.0010073184967041016 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:41] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:45] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:45] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.560976, 'recall': 0.309973, 'jaccard': 0.249458, 'f1': 0.399306, 'accuracy': 0.084337}}, 'personal': {'micro': {'accuracy': 0.08433734939759036, 'precision': 0.5365853658536586, 'recall': 0.29649595687331537, 'jaccard': 0.23605150214592274, 'f1': 0.3819444444444444}, 'macro': {'accuracy': 0.08433734939759036, 'precision': 0.4464429145152037, 'recall': 0.3108794485300509, 'jaccard': 0.24681954591593142, 'f1': 0.3340466821154277}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:45] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:45] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:45] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:49] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:49] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.284091, 'recall': 0.193798, 'jaccard': 0.130208, 'f1': 0.230415, 'accuracy': 0.120482}}, 'personal': {'micro': {'accuracy': 0.03614457831325301, 'precision': 0.20454545454545456, 'recall': 0.10285714285714286, 'jaccard': 0.07346938775510205, 'f1': 0.13688212927756654}, 'macro': {'accuracy': 0.03614457831325301, 'precision': 0.15694922547332185, 'recall': 0.10042808597025463, 'jaccard': 0.07828954847027135, 'f1': 0.11287825707532935}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:49] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:49] INFO in preprocessing: Converted to list of size 83 in 0.0003592967987060547 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:49] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:53] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:53] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.60396, 'recall': 0.383648, 'jaccard': 0.306533, 'f1': 0.469231, 'accuracy': 0.253012}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.6039603960396039, 'recall': 0.11359404096834265, 'jaccard': 0.10571923743500866, 'f1': 0.19122257053291536}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.4014056224899598, 'recall': 0.14221652996046572, 'jaccard': 0.1279781661895796, 'f1': 0.19128744778409854}}}\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:53] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:53] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:53] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:56] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:56] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:59] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-04 23:59:59] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  43%|████▎     | 3/7 [02:15<02:59, 44.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:00:02] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:00:03] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:00:04] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:00:04] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:04] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:04] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:04] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:08] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:08] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.62439, 'recall': 0.345013, 'jaccard': 0.285714, 'f1': 0.444444, 'accuracy': 0.096386}}, 'personal': {'micro': {'accuracy': 0.08433734939759036, 'precision': 0.5951219512195122, 'recall': 0.3288409703504043, 'jaccard': 0.2687224669603524, 'f1': 0.4236111111111111}, 'macro': {'accuracy': 0.08433734939759036, 'precision': 0.49986135016255495, 'recall': 0.3418422608181644, 'jaccard': 0.27990607117113137, 'f1': 0.37471190711800206}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:08] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:08] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:08] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:12] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:12] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.290323, 'recall': 0.209302, 'jaccard': 0.138462, 'f1': 0.243243, 'accuracy': 0.108434}}, 'personal': {'micro': {'accuracy': 0.024096385542168676, 'precision': 0.20430107526881722, 'recall': 0.10857142857142857, 'jaccard': 0.07630522088353414, 'f1': 0.1417910447761194}, 'macro': {'accuracy': 0.024096385542168676, 'precision': 0.15793248180692696, 'recall': 0.11011297939008781, 'jaccard': 0.07807518229204975, 'f1': 0.11770349797458231}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:12] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:12] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:12] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:15] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:15] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.481481, 'recall': 0.327044, 'jaccard': 0.24186, 'f1': 0.389513, 'accuracy': 0.240964}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.48148148148148145, 'recall': 0.09683426443202979, 'jaccard': 0.08768971332209106, 'f1': 0.16124031007751938}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.3740963855421686, 'recall': 0.11822629859957526, 'jaccard': 0.10970489839115234, 'f1': 0.164881439574032}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:15] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:15] INFO in preprocessing: Converted to list of size 70 in 0.0010387897491455078 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:15] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:18] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:18] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:21] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:21] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  57%|█████▋    | 4/7 [02:37<01:46, 35.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:00:24] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:24] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:24] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:24] INFO in entity_extractor: Fitting SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:30] INFO in entity_extractor: Evaluating SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:30] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.964052, 'recall': 0.795148, 'jaccard': 0.772251, 'f1': 0.871492, 'accuracy': 0.433735}}, 'personal': {'micro': {'accuracy': 0.43373493975903615, 'precision': 0.9640522875816994, 'recall': 0.7951482479784366, 'jaccard': 0.7722513089005235, 'f1': 0.8714918759231906}, 'macro': {'accuracy': 0.43373493975903615, 'precision': 0.7734126984126984, 'recall': 0.7035084059180444, 'jaccard': 0.6849723569603088, 'f1': 0.7287990284838358}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:30] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:30] INFO in preprocessing: Converted to list of size 83 in 0.0010018348693847656 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:30] INFO in entity_extractor: Fitting SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:34] INFO in entity_extractor: Evaluating SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:34] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.900621, 'recall': 0.562016, 'jaccard': 0.529197, 'f1': 0.692124, 'accuracy': 0.361446}}, 'personal': {'micro': {'accuracy': 0.08433734939759036, 'precision': 0.8994708994708994, 'recall': 0.4857142857142857, 'jaccard': 0.46070460704607047, 'f1': 0.6307977736549165}, 'macro': {'accuracy': 0.08433734939759036, 'precision': 0.6597389558232931, 'recall': 0.42785173327341997, 'jaccard': 0.407275856673447, 'f1': 0.5062311104125419}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:34] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:34] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:34] INFO in entity_extractor: Fitting SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:38] INFO in entity_extractor: Evaluating SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:38] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.924812, 'recall': 0.773585, 'jaccard': 0.727811, 'f1': 0.842466, 'accuracy': 0.590361}}, 'personal': {'micro': {'accuracy': 0.3132530120481928, 'precision': 0.8831967213114754, 'recall': 0.8026070763500931, 'jaccard': 0.7255892255892256, 'f1': 0.8409756097560975}, 'macro': {'accuracy': 0.3132530120481928, 'precision': 0.7554895960640156, 'recall': 0.7634882564956541, 'jaccard': 0.6885287506300506, 'f1': 0.7443714167645693}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:38] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:38] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:38] INFO in entity_extractor: Predicting SlidingWindowExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:42] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:42] INFO in entity_extractor: Predicting SlidingWindowExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:46] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:46] INFO in entity_extractor: Predicting SlidingWindowExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  71%|███████▏  | 5/7 [03:03<01:03, 31.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:00:49] INFO in spacy: Loading spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:50] INFO in spacy: Loaded spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:50] INFO in spacy: Loading spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:51] INFO in spacy: Loaded spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:51] INFO in spacy: Loading spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:51] INFO in spacy: Loaded spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:51] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:51] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:51] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:00:51] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:02] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:02] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.588843, 'recall': 0.768194, 'jaccard': 0.5, 'f1': 0.666667, 'accuracy': 0.13253}}, 'personal': {'micro': {'accuracy': 0.13253012048192772, 'precision': 0.5599173553719008, 'recall': 0.7304582210242587, 'jaccard': 0.464041095890411, 'f1': 0.6339181286549708}, 'macro': {'accuracy': 0.13253012048192772, 'precision': 0.5083155207600356, 'recall': 0.6442953632712669, 'jaccard': 0.4529758967729064, 'f1': 0.550971066309199}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:02] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:02] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:02] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:15] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:15] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.141689, 'recall': 0.20155, 'jaccard': 0.09075, 'f1': 0.1664, 'accuracy': 0.036145}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.125, 'recall': 0.13428571428571429, 'jaccard': 0.06921944035346098, 'f1': 0.12947658402203857}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.10955488621151271, 'recall': 0.13378814960140262, 'jaccard': 0.0683424045902091, 'f1': 0.11297913775329715}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:15] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:15] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:15] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:26] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:26] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.385185, 'recall': 0.327044, 'jaccard': 0.214876, 'f1': 0.353741, 'accuracy': 0.144578}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.37681159420289856, 'recall': 0.09683426443202979, 'jaccard': 0.08346709470304976, 'f1': 0.15407407407407409}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.24611780455153948, 'recall': 0.11154538976324165, 'jaccard': 0.09392877236781458, 'f1': 0.14160194649563893}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:26] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:26] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:26] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:36] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:36] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:46] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:46] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  86%|████████▌ | 6/7 [04:09<00:43, 43.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:01:56] INFO in spacy: Loading spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:57] INFO in spacy: Loaded spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:57] INFO in spacy: Loading spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:59] INFO in spacy: Loaded spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:01:59] INFO in spacy: Loading spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:00] INFO in spacy: Loaded spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:00] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:00] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:00] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:00] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:12] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:12] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.631799, 'recall': 0.814016, 'jaccard': 0.552102, 'f1': 0.711425, 'accuracy': 0.180723}}, 'personal': {'micro': {'accuracy': 0.14457831325301204, 'precision': 0.5983263598326359, 'recall': 0.77088948787062, 'jaccard': 0.5079928952042628, 'f1': 0.6737338044758538}, 'macro': {'accuracy': 0.14457831325301204, 'precision': 0.5401068722723764, 'recall': 0.6744354039534762, 'jaccard': 0.49509253210437254, 'f1': 0.5830328446364066}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:12] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:12] INFO in preprocessing: Converted to list of size 83 in 0.0010106563568115234 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:12] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:23] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:24] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.134921, 'recall': 0.197674, 'jaccard': 0.087179, 'f1': 0.160377, 'accuracy': 0.036145}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.11886304909560723, 'recall': 0.13142857142857142, 'jaccard': 0.06657018813314038, 'f1': 0.1248303934871099}, 'macro': {'accuracy': 0.0, 'precision': 0.10814661065369782, 'recall': 0.12916967570582027, 'jaccard': 0.06781105546324315, 'f1': 0.11108741042235167}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:24] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:24] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:24] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:35] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:35] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.398551, 'recall': 0.345912, 'jaccard': 0.227273, 'f1': 0.37037, 'accuracy': 0.168675}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.3873239436619718, 'recall': 0.10242085661080075, 'jaccard': 0.08814102564102565, 'f1': 0.16200294550810015}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.26408491107286286, 'recall': 0.12299117289577176, 'jaccard': 0.1046616846811744, 'f1': 0.15483553429968247}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:35] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:35] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:35] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:47] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:47] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:57] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:02:57] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models: 100%|██████████| 7/7 [05:21<00:00, 45.90s/it]\n",
      "Testing models:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:03:08] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:09] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:10] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:10] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:10] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:10] INFO in preprocessing: Converted to list of size 83 in 0.0009992122650146484 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:10] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:03:10] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:10] INFO in entity_extractor: Fitting PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:13] INFO in entity_extractor: Evaluating PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:13] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.797814, 'recall': 0.345972, 'jaccard': 0.318083, 'f1': 0.482645, 'accuracy': 0.13253}}, 'personal': {'micro': {'accuracy': 0.12048192771084337, 'precision': 0.7704918032786885, 'recall': 0.3341232227488152, 'jaccard': 0.30387931034482757, 'f1': 0.4661157024793389}, 'macro': {'accuracy': 0.12048192771084337, 'precision': 0.569391853126793, 'recall': 0.3423706350107607, 'jaccard': 0.30923537315473343, 'f1': 0.3923369660411205}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:13] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:13] INFO in preprocessing: Converted to list of size 83 in 0.0010135173797607422 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:13] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:03:14] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:14] INFO in entity_extractor: Fitting PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:17] INFO in entity_extractor: Evaluating PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:17] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.281081, 'recall': 0.197719, 'jaccard': 0.131313, 'f1': 0.232143, 'accuracy': 0.024096}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.25405405405405407, 'recall': 0.1378299120234604, 'jaccard': 0.09812108559498957, 'f1': 0.17870722433460076}, 'macro': {'accuracy': 0.0, 'precision': 0.1855056589996349, 'recall': 0.1073966194448122, 'jaccard': 0.07443089039474582, 'f1': 0.12083667966020907}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:17] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:17] INFO in preprocessing: Converted to list of size 83 in 0.0009660720825195312 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:17] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:03:17] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:17] INFO in entity_extractor: Fitting PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:20] INFO in entity_extractor: Evaluating PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:20] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.5, 'recall': 0.278571, 'jaccard': 0.217877, 'f1': 0.357798, 'accuracy': 0.168675}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.5, 'recall': 0.06759098786828423, 'jaccard': 0.0633116883116883, 'f1': 0.11908396946564885}, 'macro': {'accuracy': 0.0, 'precision': 0.3172690763052209, 'recall': 0.0858840231417497, 'jaccard': 0.0751492865192515, 'f1': 0.11899155169656529}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:20] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:20] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:20] INFO in entity_extractor: Predicting PretrainedBertEntityExtractorPure with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:23] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:23] INFO in entity_extractor: Predicting PretrainedBertEntityExtractorPure with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:25] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:25] INFO in entity_extractor: Predicting PretrainedBertEntityExtractorPure with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  14%|█▍        | 1/7 [00:20<02:01, 20.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:03:29] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:29] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:30] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:30] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:30] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:30] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:30] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:03:30] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:30] INFO in entity_extractor: Fitting PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:03:45] INFO in entity_extractor: Evaluating PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:45] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.766509, 'recall': 0.770142, 'jaccard': 0.6238, 'f1': 0.768322, 'accuracy': 0.180723}}, 'personal': {'micro': {'accuracy': 0.1566265060240964, 'precision': 0.7405660377358491, 'recall': 0.7440758293838863, 'jaccard': 0.5902255639097744, 'f1': 0.7423167848699763}, 'macro': {'accuracy': 0.1566265060240964, 'precision': 0.5506751670252733, 'recall': 0.6152576789952379, 'jaccard': 0.4906342653330605, 'f1': 0.5718015294297999}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:45] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:45] INFO in preprocessing: Converted to list of size 83 in 0.0010006427764892578 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:45] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:03:45] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:45] INFO in entity_extractor: Fitting PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:59] INFO in entity_extractor: Evaluating PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:59] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.276243, 'recall': 0.380228, 'jaccard': 0.190476, 'f1': 0.32, 'accuracy': 0.024096}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.2265193370165746, 'recall': 0.2404692082111437, 'jaccard': 0.1320450885668277, 'f1': 0.2332859174964438}, 'macro': {'accuracy': 0.0, 'precision': 0.17485408126797214, 'recall': 0.18435610574164793, 'jaccard': 0.10929330160892567, 'f1': 0.17132575086811824}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:59] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:59] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:59] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:03:59] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:03:59] INFO in entity_extractor: Fitting PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:04:14] INFO in entity_extractor: Evaluating PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:04:14] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.496732, 'recall': 0.542857, 'jaccard': 0.35023, 'f1': 0.518771, 'accuracy': 0.216867}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.48366013071895425, 'recall': 0.12824956672443674, 'jaccard': 0.11280487804878049, 'f1': 0.20273972602739726}, 'macro': {'accuracy': 0.0, 'precision': 0.3509848919487474, 'recall': 0.14135628175547443, 'jaccard': 0.12090444013960204, 'f1': 0.18481882368235833}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:04:14] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:04:14] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:04:14] INFO in entity_extractor: Predicting PretrainedBERTEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:04:29] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:04:29] INFO in entity_extractor: Predicting PretrainedBERTEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:04:48] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:04:48] INFO in entity_extractor: Predicting PretrainedBERTEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "Testing models:  29%|██▊       | 2/7 [01:58<05:29, 65.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:05:06] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:05:07] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:05:08] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:05:09] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:09] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:09] INFO in preprocessing: Converted to list of size 83 in 0.000997781753540039 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:09] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:14] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:14] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.55914, 'recall': 0.246445, 'jaccard': 0.206349, 'f1': 0.342105, 'accuracy': 0.072289}}, 'personal': {'micro': {'accuracy': 0.07228915662650602, 'precision': 0.532258064516129, 'recall': 0.23459715639810427, 'jaccard': 0.1944990176817289, 'f1': 0.3256578947368421}, 'macro': {'accuracy': 0.07228915662650602, 'precision': 0.36910021036527063, 'recall': 0.2279847255357994, 'jaccard': 0.1884686696876633, 'f1': 0.2555232555268352}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:14] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:14] INFO in preprocessing: Converted to list of size 83 in 0.0009648799896240234 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:14] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:18] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:18] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.251534, 'recall': 0.155894, 'jaccard': 0.106494, 'f1': 0.192488, 'accuracy': 0.084337}}, 'personal': {'micro': {'accuracy': 0.04819277108433735, 'precision': 0.2073170731707317, 'recall': 0.09970674486803519, 'jaccard': 0.07218683651804671, 'f1': 0.13465346534653463}, 'macro': {'accuracy': 0.04819277108433735, 'precision': 0.14725329890992542, 'recall': 0.07901385762831546, 'jaccard': 0.05552131741004881, 'f1': 0.09262077418496197}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:18] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:18] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:18] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:23] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:23] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.565217, 'recall': 0.278571, 'jaccard': 0.229412, 'f1': 0.373206, 'accuracy': 0.180723}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.5652173913043478, 'recall': 0.06759098786828423, 'jaccard': 0.0642504118616145, 'f1': 0.12074303405572756}, 'macro': {'accuracy': 0.0, 'precision': 0.3144578313253012, 'recall': 0.07896109332725362, 'jaccard': 0.074641193541279, 'f1': 0.11536477860934172}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:23] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:23] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:23] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:26] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:26] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:30] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:30] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  43%|████▎     | 3/7 [02:26<03:15, 48.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:05:34] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:05:35] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:05:36] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:05:36] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:36] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:36] INFO in preprocessing: Converted to list of size 83 in 0.0009984970092773438 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:36] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:41] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:41] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.672131, 'recall': 0.291469, 'jaccard': 0.255187, 'f1': 0.406612, 'accuracy': 0.120482}}, 'personal': {'micro': {'accuracy': 0.10843373493975904, 'precision': 0.644808743169399, 'recall': 0.2796208530805687, 'jaccard': 0.24229979466119098, 'f1': 0.39008264462809916}, 'macro': {'accuracy': 0.10843373493975904, 'precision': 0.46579651941097727, 'recall': 0.29107083621227153, 'jaccard': 0.2586664803815761, 'f1': 0.3317053454894292}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:41] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:41] INFO in preprocessing: Converted to list of size 83 in 0.0010037422180175781 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:41] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:44] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:45] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.252632, 'recall': 0.18251, 'jaccard': 0.118519, 'f1': 0.211921, 'accuracy': 0.060241}}, 'personal': {'micro': {'accuracy': 0.024096385542168676, 'precision': 0.20526315789473684, 'recall': 0.11436950146627566, 'jaccard': 0.07926829268292683, 'f1': 0.14689265536723164}, 'macro': {'accuracy': 0.024096385542168676, 'precision': 0.12010498132882405, 'recall': 0.08438148197184342, 'jaccard': 0.05819352445858471, 'f1': 0.09152230260486817}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:45] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:45] INFO in preprocessing: Converted to list of size 83 in 0.0010602474212646484 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:45] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:48] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:48] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.416667, 'recall': 0.214286, 'jaccard': 0.164835, 'f1': 0.283019, 'accuracy': 0.156627}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.4166666666666667, 'recall': 0.05199306759098787, 'jaccard': 0.048465266558966075, 'f1': 0.09244992295839753}, 'macro': {'accuracy': 0.0, 'precision': 0.24598393574297187, 'recall': 0.060129356122022436, 'jaccard': 0.05540537581148537, 'f1': 0.0873625381398409}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:48] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:48] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:48] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:52] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:52] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:55] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:55] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  57%|█████▋    | 4/7 [02:50<01:57, 39.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:05:58] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:58] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:58] INFO in preprocessing: Converted to list of size 83 in 0.0009992122650146484 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:05:58] INFO in entity_extractor: Fitting SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:05] INFO in entity_extractor: Evaluating SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:05] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.978659, 'recall': 0.760664, 'jaccard': 0.748252, 'f1': 0.856, 'accuracy': 0.313253}}, 'personal': {'micro': {'accuracy': 0.3132530120481928, 'precision': 0.9786585365853658, 'recall': 0.7606635071090048, 'jaccard': 0.7482517482517482, 'f1': 0.856}, 'macro': {'accuracy': 0.3132530120481928, 'precision': 0.7189759036144578, 'recall': 0.6321195821523218, 'jaccard': 0.6184984308805682, 'f1': 0.6645687982396045}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:05] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:05] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:05] INFO in entity_extractor: Fitting SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:09] INFO in entity_extractor: Evaluating SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:09] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.8875, 'recall': 0.539924, 'jaccard': 0.505338, 'f1': 0.671395, 'accuracy': 0.361446}}, 'personal': {'micro': {'accuracy': 0.08433734939759036, 'precision': 0.8950276243093923, 'recall': 0.4750733137829912, 'jaccard': 0.45, 'f1': 0.6206896551724138}, 'macro': {'accuracy': 0.08433734939759036, 'precision': 0.6235943775100402, 'recall': 0.37815658237344985, 'jaccard': 0.3650391108222434, 'f1': 0.46295830064819055}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:09] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:09] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:09] INFO in entity_extractor: Fitting SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:13] INFO in entity_extractor: Evaluating SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:13] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.927835, 'recall': 0.642857, 'jaccard': 0.612245, 'f1': 0.759494, 'accuracy': 0.542169}}, 'personal': {'micro': {'accuracy': 0.25301204819277107, 'precision': 0.9013761467889908, 'recall': 0.6811091854419411, 'jaccard': 0.6338709677419355, 'f1': 0.7759131293188549}, 'macro': {'accuracy': 0.25301204819277107, 'precision': 0.6647631469811296, 'recall': 0.6429579572979259, 'jaccard': 0.587452645026361, 'f1': 0.6397988585135548}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:13] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:13] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:13] INFO in entity_extractor: Predicting SlidingWindowExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:20] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:20] INFO in entity_extractor: Predicting SlidingWindowExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:23] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:23] INFO in entity_extractor: Predicting SlidingWindowExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  71%|███████▏  | 5/7 [03:19<01:10, 35.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:06:27] INFO in spacy: Loading spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:28] INFO in spacy: Loaded spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:28] INFO in spacy: Loading spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:29] INFO in spacy: Loaded spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:29] INFO in spacy: Loading spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:30] INFO in spacy: Loaded spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:30] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:30] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:30] INFO in preprocessing: Converted to list of size 83 in 0.0009965896606445312 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:30] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:44] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:44] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.712297, 'recall': 0.727488, 'jaccard': 0.562271, 'f1': 0.719812, 'accuracy': 0.096386}}, 'personal': {'micro': {'accuracy': 0.0963855421686747, 'precision': 0.6851851851851852, 'recall': 0.7014218009478673, 'jaccard': 0.5304659498207885, 'f1': 0.6932084309133489}, 'macro': {'accuracy': 0.0963855421686747, 'precision': 0.5257489832791038, 'recall': 0.5993042222023364, 'jaccard': 0.45591479175678673, 'f1': 0.5460857191067162}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:44] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:44] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:44] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:58] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:58] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.121547, 'recall': 0.1673, 'jaccard': 0.075731, 'f1': 0.1408, 'accuracy': 0.060241}}, 'personal': {'micro': {'accuracy': 0.024096385542168676, 'precision': 0.11141304347826086, 'recall': 0.12023460410557185, 'jaccard': 0.061377245508982034, 'f1': 0.1156558533145275}, 'macro': {'accuracy': 0.024096385542168676, 'precision': 0.08155240007649646, 'recall': 0.09806147667593451, 'jaccard': 0.050483921516327, 'f1': 0.08616603709592296}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:58] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:58] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:06:58] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:07:11] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:07:11] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.369369, 'recall': 0.292857, 'jaccard': 0.195238, 'f1': 0.326693, 'accuracy': 0.156627}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.36607142857142855, 'recall': 0.07105719237435008, 'jaccard': 0.06327160493827161, 'f1': 0.11901306240928883}, 'macro': {'accuracy': 0.0, 'precision': 0.1963855421686747, 'recall': 0.06596661699964938, 'jaccard': 0.05815362991637749, 'f1': 0.09135786189405641}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:07:11] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:07:11] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:07:11] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:07:23] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:07:23] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:07:34] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:07:34] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  86%|████████▌ | 6/7 [04:38<00:50, 50.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:07:46] INFO in spacy: Loading spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:07:48] INFO in spacy: Loaded spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:07:48] INFO in spacy: Loading spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:07:50] INFO in spacy: Loaded spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:07:50] INFO in spacy: Loading spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:07:52] INFO in spacy: Loaded spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:07:52] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:07:52] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:07:52] INFO in preprocessing: Converted to list of size 83 in 0.0010030269622802734 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:07:52] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:08:07] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:08:07] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.753488, 'recall': 0.767773, 'jaccard': 0.613636, 'f1': 0.760563, 'accuracy': 0.13253}}, 'personal': {'micro': {'accuracy': 0.12048192771084337, 'precision': 0.7238979118329466, 'recall': 0.7393364928909952, 'jaccard': 0.5767097966728281, 'f1': 0.731535756154748}, 'macro': {'accuracy': 0.12048192771084337, 'precision': 0.5489458053561527, 'recall': 0.6153756834807124, 'jaccard': 0.4796578078442377, 'f1': 0.5651858111591783}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:08:07] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:08:07] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:08:07] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:08:21] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:08:21] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.136364, 'recall': 0.18251, 'jaccard': 0.084656, 'f1': 0.156098, 'accuracy': 0.084337}}, 'personal': {'micro': {'accuracy': 0.03614457831325301, 'precision': 0.12324929971988796, 'recall': 0.12903225806451613, 'jaccard': 0.0672782874617737, 'f1': 0.12607449856733524}, 'macro': {'accuracy': 0.03614457831325301, 'precision': 0.0921488730578029, 'recall': 0.1058299130588287, 'jaccard': 0.05672461651955073, 'f1': 0.0950059530553922}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:08:21] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:08:21] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:08:21] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:08:37] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:08:37] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.362832, 'recall': 0.292857, 'jaccard': 0.193396, 'f1': 0.324111, 'accuracy': 0.168675}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.3565217391304348, 'recall': 0.07105719237435008, 'jaccard': 0.0629800307219662, 'f1': 0.11849710982658959}, 'macro': {'accuracy': 0.0, 'precision': 0.20755402562631478, 'recall': 0.0704628628526265, 'jaccard': 0.06382121874503165, 'f1': 0.10037075782254638}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:08:37] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:08:37] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:08:37] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:08:49] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:08:49] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:02] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:02] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models: 100%|██████████| 7/7 [06:06<00:00, 52.34s/it]\n",
      "Testing models:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:09:16] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:16] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:17] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:17] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:17] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:17] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:17] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:09:18] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:18] INFO in entity_extractor: Fitting PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:22] INFO in entity_extractor: Evaluating PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:22] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.71028, 'recall': 0.336283, 'jaccard': 0.29572, 'f1': 0.456456, 'accuracy': 0.108434}}, 'personal': {'micro': {'accuracy': 0.10843373493975904, 'precision': 0.6962616822429907, 'recall': 0.32964601769911506, 'jaccard': 0.28820116054158607, 'f1': 0.44744744744744747}, 'macro': {'accuracy': 0.10843373493975904, 'precision': 0.6362880091795755, 'recall': 0.4126118403543895, 'jaccard': 0.35425085729461125, 'f1': 0.4528304905127988}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:22] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:22] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:22] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:09:22] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:22] INFO in entity_extractor: Fitting PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:26] INFO in entity_extractor: Evaluating PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:26] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.320442, 'recall': 0.205674, 'jaccard': 0.14321, 'f1': 0.25054, 'accuracy': 0.060241}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.2596685082872928, 'recall': 0.125, 'jaccard': 0.09215686274509804, 'f1': 0.1687612208258528}, 'macro': {'accuracy': 0.0, 'precision': 0.24162363740676987, 'recall': 0.11878987812722752, 'jaccard': 0.08565631155992602, 'f1': 0.138931951582554}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:26] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:26] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:26] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:09:27] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:27] INFO in entity_extractor: Fitting PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:31] INFO in entity_extractor: Evaluating PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:31] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.611111, 'recall': 0.390533, 'jaccard': 0.312796, 'f1': 0.476534, 'accuracy': 0.228916}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.6, 'recall': 0.10696920583468396, 'jaccard': 0.09984871406959153, 'f1': 0.1815680880330124}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.4170682730923695, 'recall': 0.1472307446243438, 'jaccard': 0.12724111859476847, 'f1': 0.18953596145894536}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:31] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:31] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:31] INFO in entity_extractor: Predicting PretrainedBertEntityExtractorPure with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:34] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:34] INFO in entity_extractor: Predicting PretrainedBertEntityExtractorPure with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:38] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:38] INFO in entity_extractor: Predicting PretrainedBertEntityExtractorPure with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  14%|█▍        | 1/7 [00:26<02:37, 26.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:09:41] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:42] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:43] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:43] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:43] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:43] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:43] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:09:43] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:09:43] INFO in entity_extractor: Fitting PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:10:03] INFO in entity_extractor: Evaluating PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:10:03] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.665493, 'recall': 0.836283, 'jaccard': 0.588785, 'f1': 0.741176, 'accuracy': 0.13253}}, 'personal': {'micro': {'accuracy': 0.13253012048192772, 'precision': 0.6432337434094904, 'recall': 0.8097345132743363, 'jaccard': 0.5587786259541985, 'f1': 0.7169441723800196}, 'macro': {'accuracy': 0.13253012048192772, 'precision': 0.5866491373419084, 'recall': 0.7310975081425304, 'jaccard': 0.5283658351065913, 'f1': 0.6290254316674995}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:10:03] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:10:03] INFO in preprocessing: Converted to list of size 83 in 0.0010075569152832031 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:10:03] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:10:04] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:10:04] INFO in entity_extractor: Fitting PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:10:25] INFO in entity_extractor: Evaluating PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:10:25] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.317259, 'recall': 0.443262, 'jaccard': 0.22686, 'f1': 0.369822, 'accuracy': 0.024096}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.25569620253164554, 'recall': 0.26861702127659576, 'jaccard': 0.15074626865671642, 'f1': 0.2619974059662776}, 'macro': {'accuracy': 0.0, 'precision': 0.21473650473473294, 'recall': 0.22703019871694566, 'jaccard': 0.1332947472245842, 'f1': 0.20660142529852976}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:10:25] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:10:25] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:10:25] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:10:25] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:10:25] INFO in entity_extractor: Fitting PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:10:45] INFO in entity_extractor: Evaluating PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:10:45] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.561905, 'recall': 0.698225, 'jaccard': 0.452107, 'f1': 0.622691, 'accuracy': 0.216867}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.5497630331753555, 'recall': 0.1880064829821718, 'jaccard': 0.16292134831460675, 'f1': 0.28019323671497587}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.4711417096959266, 'recall': 0.23111781931208247, 'jaccard': 0.1853844660535721, 'f1': 0.2747483470617493}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:10:45] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:10:45] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:10:45] INFO in entity_extractor: Predicting PretrainedBERTEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:11:02] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:02] INFO in entity_extractor: Predicting PretrainedBERTEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:11:19] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:19] INFO in entity_extractor: Predicting PretrainedBERTEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "Testing models:  29%|██▊       | 2/7 [02:22<06:34, 78.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:11:36] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:11:38] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:11:39] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:11:40] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:40] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:40] INFO in preprocessing: Converted to list of size 83 in 0.0015091896057128906 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:40] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:44] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:44] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.518692, 'recall': 0.245575, 'jaccard': 0.2, 'f1': 0.333333, 'accuracy': 0.084337}}, 'personal': {'micro': {'accuracy': 0.08433734939759036, 'precision': 0.5093457943925234, 'recall': 0.2411504424778761, 'jaccard': 0.19569120287253142, 'f1': 0.32732732732732733}, 'macro': {'accuracy': 0.08433734939759036, 'precision': 0.47475028318401813, 'recall': 0.311303900777585, 'jaccard': 0.24970367651090544, 'f1': 0.3369299311147198}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:44] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:44] INFO in preprocessing: Converted to list of size 83 in 0.0015075206756591797 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:44] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:49] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:49] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.276316, 'recall': 0.148936, 'jaccard': 0.107143, 'f1': 0.193548, 'accuracy': 0.072289}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.20915032679738563, 'recall': 0.0851063829787234, 'jaccard': 0.06438631790744467, 'f1': 0.12098298676748581}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.17640562248995983, 'recall': 0.07585145777916863, 'jaccard': 0.056865020560980875, 'f1': 0.09484692014812497}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:49] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:49] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:49] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:54] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:54] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.631579, 'recall': 0.426036, 'jaccard': 0.341232, 'f1': 0.508834, 'accuracy': 0.180723}}, 'personal': {'micro': {'accuracy': 0.024096385542168676, 'precision': 0.6260869565217392, 'recall': 0.1166936790923825, 'jaccard': 0.10909090909090909, 'f1': 0.19672131147540983}, 'macro': {'accuracy': 0.024096385542168676, 'precision': 0.4061675272518646, 'recall': 0.14808995779565365, 'jaccard': 0.1299218532711868, 'f1': 0.19090754304147978}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:54] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:54] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:54] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:58] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:11:58] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:02] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:02] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  43%|████▎     | 3/7 [02:51<03:44, 56.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:12:05] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:12:06] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:12:07] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:12:08] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:08] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:08] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:08] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:12] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:12] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.591549, 'recall': 0.278761, 'jaccard': 0.233766, 'f1': 0.378947, 'accuracy': 0.096386}}, 'personal': {'micro': {'accuracy': 0.0963855421686747, 'precision': 0.5774647887323944, 'recall': 0.2721238938053097, 'jaccard': 0.22693726937269373, 'f1': 0.36992481203007516}, 'macro': {'accuracy': 0.0963855421686747, 'precision': 0.5489672977624785, 'recall': 0.3570296609611765, 'jaccard': 0.2957941656736837, 'f1': 0.3915836717358594}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:12] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:12] INFO in preprocessing: Converted to list of size 83 in 0.001047372817993164 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:12] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:17] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:17] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.245614, 'recall': 0.148936, 'jaccard': 0.10219, 'f1': 0.18543, 'accuracy': 0.072289}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.1744186046511628, 'recall': 0.0797872340425532, 'jaccard': 0.05791505791505792, 'f1': 0.10948905109489052}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.14016064257028113, 'recall': 0.07123298388358629, 'jaccard': 0.05443679479824059, 'f1': 0.08707410394157382}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:17] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:17] INFO in preprocessing: Converted to list of size 83 in 0.0010437965393066406 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:17] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:21] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:21] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.6, 'recall': 0.35503, 'jaccard': 0.287081, 'f1': 0.446097, 'accuracy': 0.192771}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.59, 'recall': 0.09562398703403566, 'jaccard': 0.08966565349544073, 'f1': 0.16457461645746166}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.37630522088353413, 'recall': 0.12288534509989991, 'jaccard': 0.10849889047089616, 'f1': 0.1622500781221252}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:21] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:21] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:21] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:25] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:25] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:30] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:30] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  57%|█████▋    | 4/7 [03:19<02:15, 45.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:12:34] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:34] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:34] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:34] INFO in entity_extractor: Fitting SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:43] INFO in entity_extractor: Evaluating SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:43] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.936869, 'recall': 0.820796, 'jaccard': 0.777778, 'f1': 0.875, 'accuracy': 0.421687}}, 'personal': {'micro': {'accuracy': 0.42168674698795183, 'precision': 0.9368686868686869, 'recall': 0.8207964601769911, 'jaccard': 0.7777777777777778, 'f1': 0.8749999999999999}, 'macro': {'accuracy': 0.42168674698795183, 'precision': 0.8103413654618473, 'recall': 0.7675105596158228, 'jaccard': 0.7315707631338576, 'f1': 0.7788335586667327}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:43] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:43] INFO in preprocessing: Converted to list of size 83 in 0.0010173320770263672 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:43] INFO in entity_extractor: Fitting SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:49] INFO in entity_extractor: Evaluating SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:49] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.848958, 'recall': 0.578014, 'jaccard': 0.524116, 'f1': 0.687764, 'accuracy': 0.253012}}, 'personal': {'micro': {'accuracy': 0.07228915662650602, 'precision': 0.8532110091743119, 'recall': 0.4946808510638298, 'jaccard': 0.45588235294117646, 'f1': 0.6262626262626262}, 'macro': {'accuracy': 0.07228915662650602, 'precision': 0.6870290686555747, 'recall': 0.44151019663067853, 'jaccard': 0.4180531650411169, 'f1': 0.522892160206122}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:49] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:49] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:49] INFO in entity_extractor: Fitting SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:55] INFO in entity_extractor: Evaluating SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:55] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.952381, 'recall': 0.828402, 'jaccard': 0.795455, 'f1': 0.886076, 'accuracy': 0.638554}}, 'personal': {'micro': {'accuracy': 0.3373493975903614, 'precision': 0.9087719298245615, 'recall': 0.839546191247974, 'jaccard': 0.7742899850523169, 'f1': 0.8727885425442292}, 'macro': {'accuracy': 0.3373493975903614, 'precision': 0.8337003524578368, 'recall': 0.8229428072414571, 'jaccard': 0.7521807943725489, 'f1': 0.8105951460059693}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:55] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:55] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:12:55] INFO in entity_extractor: Predicting SlidingWindowExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:02] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:02] INFO in entity_extractor: Predicting SlidingWindowExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:06] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:06] INFO in entity_extractor: Predicting SlidingWindowExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  71%|███████▏  | 5/7 [03:57<01:24, 42.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:13:11] INFO in spacy: Loading spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:13] INFO in spacy: Loaded spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:13] INFO in spacy: Loading spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:14] INFO in spacy: Loaded spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:14] INFO in spacy: Loading spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:14] INFO in spacy: Loaded spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:14] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:14] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:14] INFO in preprocessing: Converted to list of size 83 in 0.0009632110595703125 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:14] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:31] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:31] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.629565, 'recall': 0.800885, 'jaccard': 0.544361, 'f1': 0.704966, 'accuracy': 0.084337}}, 'personal': {'micro': {'accuracy': 0.08433734939759036, 'precision': 0.6069565217391304, 'recall': 0.7721238938053098, 'jaccard': 0.5147492625368731, 'f1': 0.679649464459591}, 'macro': {'accuracy': 0.08433734939759036, 'precision': 0.5421682664462607, 'recall': 0.7066743075145104, 'jaccard': 0.48193688922279865, 'f1': 0.5944367040124635}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:31] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:31] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:31] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:47] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:47] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.106173, 'recall': 0.152482, 'jaccard': 0.06677, 'f1': 0.125182, 'accuracy': 0.048193}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.09685230024213075, 'recall': 0.10638297872340426, 'jaccard': 0.0534045393858478, 'f1': 0.10139416983523447}, 'macro': {'accuracy': 0.0, 'precision': 0.07000713476617092, 'recall': 0.08451555138302126, 'jaccard': 0.04238787164191139, 'f1': 0.07300703801319268}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:47] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:47] INFO in preprocessing: Converted to list of size 83 in 0.0009577274322509766 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:13:47] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:14:03] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:14:03] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.363057, 'recall': 0.337278, 'jaccard': 0.211896, 'f1': 0.349693, 'accuracy': 0.120482}}, 'personal': {'micro': {'accuracy': 0.024096385542168676, 'precision': 0.3584905660377358, 'recall': 0.09238249594813615, 'jaccard': 0.07927677329624479, 'f1': 0.14690721649484537}, 'macro': {'accuracy': 0.024096385542168676, 'precision': 0.24266112067316886, 'recall': 0.11452804368802727, 'jaccard': 0.09619741516575724, 'f1': 0.13506046899664714}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:14:03] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:14:03] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:14:03] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:14:15] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:14:15] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:14:26] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:14:26] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  86%|████████▌ | 6/7 [05:23<00:57, 57.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:14:38] INFO in spacy: Loading spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:14:40] INFO in spacy: Loaded spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:14:40] INFO in spacy: Loading spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:14:42] INFO in spacy: Loaded spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:14:42] INFO in spacy: Loading spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:14:44] INFO in spacy: Loaded spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:14:44] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:14:44] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:14:44] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:14:44] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:02] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:02] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.666081, 'recall': 0.838496, 'jaccard': 0.590343, 'f1': 0.742409, 'accuracy': 0.144578}}, 'personal': {'micro': {'accuracy': 0.14457831325301204, 'precision': 0.6397188049209139, 'recall': 0.8053097345132744, 'jaccard': 0.5540334855403348, 'f1': 0.7130264446620962}, 'macro': {'accuracy': 0.14457831325301204, 'precision': 0.58671755725124, 'recall': 0.7295636671508581, 'jaccard': 0.5279789395389728, 'f1': 0.6272323380953928}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:02] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:02] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:02] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:19] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:19] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.108911, 'recall': 0.156028, 'jaccard': 0.068536, 'f1': 0.12828, 'accuracy': 0.036145}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.09951456310679611, 'recall': 0.10904255319148937, 'jaccard': 0.05488621151271754, 'f1': 0.10406091370558375}, 'macro': {'accuracy': 0.0, 'precision': 0.07217857935434122, 'recall': 0.09053964776856342, 'jaccard': 0.045263589159295826, 'f1': 0.07666718510325764}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:19] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:19] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:19] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:37] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:37] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.3625, 'recall': 0.343195, 'jaccard': 0.214022, 'f1': 0.352584, 'accuracy': 0.156627}}, 'personal': {'micro': {'accuracy': 0.024096385542168676, 'precision': 0.35802469135802467, 'recall': 0.0940032414910859, 'jaccard': 0.08044382801664356, 'f1': 0.1489088575096277}, 'macro': {'accuracy': 0.024096385542168676, 'precision': 0.2404331612162937, 'recall': 0.12046086588590971, 'jaccard': 0.10096226679323775, 'f1': 0.14138053301969702}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:37] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:37] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:37] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:48] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:48] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:57] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:15:57] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models: 100%|██████████| 7/7 [06:52<00:00, 58.97s/it]\n",
      "Testing models:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:16:08] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:08] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:09] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:09] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:09] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:09] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:09] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:16:09] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:09] INFO in entity_extractor: Fitting PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:14] INFO in entity_extractor: Evaluating PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:14] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.703518, 'recall': 0.359897, 'jaccard': 0.3125, 'f1': 0.47619, 'accuracy': 0.144578}}, 'personal': {'micro': {'accuracy': 0.14457831325301204, 'precision': 0.6884422110552764, 'recall': 0.35218508997429304, 'jaccard': 0.30376940133037694, 'f1': 0.4659863945578231}, 'macro': {'accuracy': 0.14457831325301204, 'precision': 0.5361732644865175, 'recall': 0.3912283579965751, 'jaccard': 0.328301759829013, 'f1': 0.41117489905153287}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:14] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:14] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:14] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:16:14] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:14] INFO in entity_extractor: Fitting PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:18] INFO in entity_extractor: Evaluating PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:18] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.302564, 'recall': 0.212996, 'jaccard': 0.142857, 'f1': 0.25, 'accuracy': 0.048193}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.2358974358974359, 'recall': 0.12777777777777777, 'jaccard': 0.09037328094302555, 'f1': 0.16576576576576577}, 'macro': {'accuracy': 0.0, 'precision': 0.20593803786574869, 'recall': 0.11409208261617902, 'jaccard': 0.0817782953325122, 'f1': 0.12858092376164662}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:18] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:18] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:18] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:16:18] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:18] INFO in entity_extractor: Fitting PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:22] INFO in entity_extractor: Evaluating PretrainedBertEntityExtractorPure with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:22] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.584158, 'recall': 0.36646, 'jaccard': 0.29064, 'f1': 0.450382, 'accuracy': 0.192771}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.5784313725490197, 'recall': 0.09688013136288999, 'jaccard': 0.09049079754601227, 'f1': 0.16596343178621661}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.3827309236947791, 'recall': 0.1355663787418941, 'jaccard': 0.1229609224775919, 'f1': 0.1788100552531792}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:22] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:22] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:22] INFO in entity_extractor: Predicting PretrainedBertEntityExtractorPure with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:25] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:25] INFO in entity_extractor: Predicting PretrainedBertEntityExtractorPure with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:28] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:28] INFO in entity_extractor: Predicting PretrainedBertEntityExtractorPure with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  14%|█▍        | 1/7 [00:24<02:26, 24.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:16:32] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:33] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:34] INFO in pretrained: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:34] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:34] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:34] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:34] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:16:35] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:35] INFO in entity_extractor: Fitting PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:16:51] INFO in entity_extractor: Evaluating PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:51] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.656904, 'recall': 0.807198, 'jaccard': 0.567812, 'f1': 0.724337, 'accuracy': 0.156627}}, 'personal': {'micro': {'accuracy': 0.14457831325301204, 'precision': 0.6276150627615062, 'recall': 0.7712082262210797, 'jaccard': 0.5291005291005291, 'f1': 0.6920415224913493}, 'macro': {'accuracy': 0.14457831325301204, 'precision': 0.4903498893513644, 'recall': 0.6256239103823951, 'jaccard': 0.4516234224131029, 'f1': 0.5309755367795246}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:51] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:51] INFO in preprocessing: Converted to list of size 83 in 0.0009963512420654297 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:51] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:16:52] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:16:52] INFO in entity_extractor: Fitting PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:17:08] INFO in entity_extractor: Evaluating PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:17:08] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.323834, 'recall': 0.451264, 'jaccard': 0.232342, 'f1': 0.377074, 'accuracy': 0.036145}}, 'personal': {'micro': {'accuracy': 0.0, 'precision': 0.26098191214470284, 'recall': 0.28055555555555556, 'jaccard': 0.1563467492260062, 'f1': 0.27041499330655955}, 'macro': {'accuracy': 0.0, 'precision': 0.19833088893152676, 'recall': 0.20033228150698032, 'jaccard': 0.11821836737169145, 'f1': 0.18480839243742603}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:17:08] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:17:08] INFO in preprocessing: Converted to list of size 83 in 0.0009639263153076172 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:17:08] INFO in pretrained: Loading model from: c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\pretrained\\distilbert_ner_finetuned\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:17:09] INFO in pretrained: Model loaded successfully\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:17:09] INFO in entity_extractor: Fitting PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:17:25] INFO in entity_extractor: Evaluating PretrainedBERTEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:17:25] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.494949, 'recall': 0.608696, 'jaccard': 0.375479, 'f1': 0.545961, 'accuracy': 0.144578}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.49246231155778897, 'recall': 0.16091954022988506, 'jaccard': 0.13802816901408452, 'f1': 0.24257425742574257}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.3751004016064257, 'recall': 0.20100869294395315, 'jaccard': 0.1611199707135011, 'f1': 0.23726136533272194}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:17:25] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:17:25] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:17:25] INFO in entity_extractor: Predicting PretrainedBERTEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:17:41] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:17:41] INFO in entity_extractor: Predicting PretrainedBERTEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:18:01] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:01] INFO in entity_extractor: Predicting PretrainedBERTEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\.venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "Testing models:  29%|██▊       | 2/7 [02:11<06:05, 73.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:18:18] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:18:20] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:18:21] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:18:22] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:22] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:22] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:22] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:27] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:27] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.527919, 'recall': 0.267352, 'jaccard': 0.215768, 'f1': 0.354949, 'accuracy': 0.084337}}, 'personal': {'micro': {'accuracy': 0.08433734939759036, 'precision': 0.5126903553299492, 'recall': 0.2596401028277635, 'jaccard': 0.20824742268041238, 'f1': 0.3447098976109215}, 'macro': {'accuracy': 0.08433734939759036, 'precision': 0.39935456110154904, 'recall': 0.2882495716598719, 'jaccard': 0.22587158490772946, 'f1': 0.30148452141517784}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:27] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:27] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:27] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:31] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:31] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.289773, 'recall': 0.184116, 'jaccard': 0.126866, 'f1': 0.225166, 'accuracy': 0.120482}}, 'personal': {'micro': {'accuracy': 0.04819277108433735, 'precision': 0.20786516853932585, 'recall': 0.10277777777777777, 'jaccard': 0.07385229540918163, 'f1': 0.13754646840148696}, 'macro': {'accuracy': 0.04819277108433735, 'precision': 0.15491967871485943, 'recall': 0.08030933256836872, 'jaccard': 0.060050868039789665, 'f1': 0.09666325322427992}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:31] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:31] INFO in preprocessing: Converted to list of size 83 in 0.0011794567108154297 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:31] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:35] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:35] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.565657, 'recall': 0.347826, 'jaccard': 0.27451, 'f1': 0.430769, 'accuracy': 0.156627}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.56, 'recall': 0.09195402298850575, 'jaccard': 0.08575803981623277, 'f1': 0.15796897038081806}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.3370912220309811, 'recall': 0.1209040881228352, 'jaccard': 0.10942271263991579, 'f1': 0.1606803725358499}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:35] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:35] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:35] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:39] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:39] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:43] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:43] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  43%|████▎     | 3/7 [02:39<03:30, 52.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:18:47] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:18:48] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:18:48] INFO in huggingface: CUDA is available. Using GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:18:49] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:49] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:49] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:49] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:53] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:53] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.536946, 'recall': 0.280206, 'jaccard': 0.225673, 'f1': 0.368243, 'accuracy': 0.108434}}, 'personal': {'micro': {'accuracy': 0.10843373493975904, 'precision': 0.5221674876847291, 'recall': 0.27249357326478146, 'jaccard': 0.21810699588477367, 'f1': 0.35810810810810806}, 'macro': {'accuracy': 0.10843373493975904, 'precision': 0.42433717554199485, 'recall': 0.3175955269094416, 'jaccard': 0.25249982240768915, 'f1': 0.3299313849329703}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:53] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:53] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:53] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:57] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:57] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.245902, 'recall': 0.162455, 'jaccard': 0.108434, 'f1': 0.195652, 'accuracy': 0.108434}}, 'personal': {'micro': {'accuracy': 0.03614457831325301, 'precision': 0.16304347826086957, 'recall': 0.08333333333333333, 'jaccard': 0.058365758754863814, 'f1': 0.11029411764705883}, 'macro': {'accuracy': 0.03614457831325301, 'precision': 0.12981014968966775, 'recall': 0.06128561866513673, 'jaccard': 0.04908330062103049, 'f1': 0.07781776456475252}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:57] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:57] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:18:57] INFO in entity_extractor: Fitting HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:01] INFO in entity_extractor: Evaluating HuggingFaceEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:02] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.462366, 'recall': 0.267081, 'jaccard': 0.203791, 'f1': 0.338583, 'accuracy': 0.13253}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.46236559139784944, 'recall': 0.07060755336617405, 'jaccard': 0.06525037936267071, 'f1': 0.12250712250712249}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.28273092369477915, 'recall': 0.09421331098910983, 'jaccard': 0.08439862399279012, 'f1': 0.12767026175727395}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:02] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:02] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:02] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:05] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:05] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:09] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:09] INFO in entity_extractor: Predicting HuggingFaceEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  57%|█████▋    | 4/7 [03:05<02:05, 41.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:19:12] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:12] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:12] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:12] INFO in entity_extractor: Fitting SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:19] INFO in entity_extractor: Evaluating SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:19] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.944272, 'recall': 0.784062, 'jaccard': 0.749386, 'f1': 0.856742, 'accuracy': 0.39759}}, 'personal': {'micro': {'accuracy': 0.39759036144578314, 'precision': 0.9442724458204335, 'recall': 0.7840616966580977, 'jaccard': 0.7493857493857494, 'f1': 0.8567415730337079}, 'macro': {'accuracy': 0.39759036144578314, 'precision': 0.6708835341365462, 'recall': 0.6417988666175923, 'jaccard': 0.6100576159004379, 'f1': 0.6499977206036739}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:19] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:19] INFO in preprocessing: Converted to list of size 83 in 0.0009551048278808594 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:19] INFO in entity_extractor: Fitting SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:24] INFO in entity_extractor: Evaluating SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:24] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.883041, 'recall': 0.545126, 'jaccard': 0.508418, 'f1': 0.674107, 'accuracy': 0.26506}}, 'personal': {'micro': {'accuracy': 0.08433734939759036, 'precision': 0.8756476683937824, 'recall': 0.46944444444444444, 'jaccard': 0.4401041666666667, 'f1': 0.6112115732368897}, 'macro': {'accuracy': 0.08433734939759036, 'precision': 0.5862074672315636, 'recall': 0.35444635685599546, 'jaccard': 0.33712254160517807, 'f1': 0.43029152793382114}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:24] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:24] INFO in preprocessing: Converted to list of size 83 in 0.0009586811065673828 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:24] INFO in entity_extractor: Fitting SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:29] INFO in entity_extractor: Evaluating SlidingWindowExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:29] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.92562, 'recall': 0.695652, 'jaccard': 0.658824, 'f1': 0.794326, 'accuracy': 0.493976}}, 'personal': {'micro': {'accuracy': 0.25301204819277107, 'precision': 0.8777555110220441, 'recall': 0.7192118226600985, 'jaccard': 0.6537313432835821, 'f1': 0.7906137184115524}, 'macro': {'accuracy': 0.25301204819277107, 'precision': 0.7340670437304111, 'recall': 0.6907633047577737, 'jaccard': 0.6225341150679687, 'f1': 0.6861726364379329}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:29] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:29] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:29] INFO in entity_extractor: Predicting SlidingWindowExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:36] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:36] INFO in entity_extractor: Predicting SlidingWindowExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:43] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:43] INFO in entity_extractor: Predicting SlidingWindowExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  71%|███████▏  | 5/7 [03:45<01:22, 41.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:19:52] INFO in spacy: Loading spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:54] INFO in spacy: Loaded spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:54] INFO in spacy: Loading spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:55] INFO in spacy: Loaded spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:55] INFO in spacy: Loading spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:57] INFO in spacy: Loaded spacy model 'en_core_web_sm'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:57] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:57] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:57] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:19:57] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:20:14] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:20:14] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.625767, 'recall': 0.786632, 'jaccard': 0.534965, 'f1': 0.697039, 'accuracy': 0.13253}}, 'personal': {'micro': {'accuracy': 0.12048192771084337, 'precision': 0.5930470347648262, 'recall': 0.7455012853470437, 'jaccard': 0.4931972789115646, 'f1': 0.6605922551252849}, 'macro': {'accuracy': 0.12048192771084337, 'precision': 0.4714493908328069, 'recall': 0.6141961320609552, 'jaccard': 0.4294412984605036, 'f1': 0.5151194191812203}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:20:14] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:20:14] INFO in preprocessing: Converted to list of size 83 in 0.0010128021240234375 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:20:14] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:20:34] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:20:34] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.110236, 'recall': 0.151625, 'jaccard': 0.068182, 'f1': 0.12766, 'accuracy': 0.072289}}, 'personal': {'micro': {'accuracy': 0.03614457831325301, 'precision': 0.09487179487179487, 'recall': 0.10277777777777777, 'jaccard': 0.051893408134642355, 'f1': 0.09866666666666665}, 'macro': {'accuracy': 0.03614457831325301, 'precision': 0.06058645610008957, 'recall': 0.07114410021036525, 'jaccard': 0.035730578689437714, 'f1': 0.062327167750569144}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:20:34] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:20:34] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:20:34] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:20:52] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:20:52] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.35, 'recall': 0.304348, 'jaccard': 0.194444, 'f1': 0.325581, 'accuracy': 0.13253}}, 'personal': {'micro': {'accuracy': 0.024096385542168676, 'precision': 0.34507042253521125, 'recall': 0.08045977011494253, 'jaccard': 0.0698005698005698, 'f1': 0.13049267643142476}, 'macro': {'accuracy': 0.024096385542168676, 'precision': 0.23447121820615793, 'recall': 0.10141813065271606, 'jaccard': 0.08654713056266639, 'f1': 0.12498860891844592}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:20:52] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:20:52] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:20:52] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:21:05] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:21:05] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:21:18] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:21:18] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  86%|████████▌ | 6/7 [05:23<01:00, 60.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-08-05 00:21:30] INFO in spacy: Loading spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:21:33] INFO in spacy: Loaded spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:21:33] INFO in spacy: Loading spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:21:35] INFO in spacy: Loaded spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:21:35] INFO in spacy: Loading spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:21:37] INFO in spacy: Loaded spacy model 'en_core_web_md'\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:21:37] INFO in entity_extractor: Fitting MultiEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:21:37] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:21:37] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:21:37] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:21:55] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:21:55] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.665281, 'recall': 0.822622, 'jaccard': 0.581818, 'f1': 0.735632, 'accuracy': 0.156627}}, 'personal': {'micro': {'accuracy': 0.14457831325301204, 'precision': 0.6278586278586279, 'recall': 0.7763496143958869, 'jaccard': 0.5316901408450704, 'f1': 0.6942528735632184}, 'macro': {'accuracy': 0.14457831325301204, 'precision': 0.49743696666437165, 'recall': 0.6314424225262085, 'jaccard': 0.4591360948288659, 'f1': 0.5365784916232527}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:21:55] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:21:55] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:21:55] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:22:10] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:22:10] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.111111, 'recall': 0.158845, 'jaccard': 0.069952, 'f1': 0.130758, 'accuracy': 0.096386}}, 'personal': {'micro': {'accuracy': 0.03614457831325301, 'precision': 0.09582309582309582, 'recall': 0.10833333333333334, 'jaccard': 0.05357142857142857, 'f1': 0.1016949152542373}, 'macro': {'accuracy': 0.03614457831325301, 'precision': 0.0645321290253962, 'recall': 0.07704867087397207, 'jaccard': 0.038560344507668556, 'f1': 0.06583796059295526}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:22:10] INFO in preprocessing: Converted to list of size 83 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:22:10] INFO in preprocessing: Converted to list of size 83 in 0.0010008811950683594 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:22:10] INFO in entity_extractor: Fitting SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:22:24] INFO in entity_extractor: Evaluating SpacyEntityExtractor with 83 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:22:24] INFO in entity_extractor: Evaluation results: {'toptal': {'multi_word': {'precision': 0.352113, 'recall': 0.310559, 'jaccard': 0.197628, 'f1': 0.330033, 'accuracy': 0.144578}}, 'personal': {'micro': {'accuracy': 0.012048192771084338, 'precision': 0.3448275862068966, 'recall': 0.08210180623973727, 'jaccard': 0.07102272727272728, 'f1': 0.1326259946949602}, 'macro': {'accuracy': 0.012048192771084338, 'precision': 0.21706827309236948, 'recall': 0.10543419490974418, 'jaccard': 0.08491712535830183, 'f1': 0.12496104572646032}}}\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:22:24] INFO in entity_extractor: Predicting MultiEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:22:24] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:22:24] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:22:38] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:22:38] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:22:55] INFO in preprocessing: Converted to list of size 70 in 0.0 seconds\u001b[0m\n",
      "\u001b[32m[2025-08-05 00:22:55] INFO in entity_extractor: Predicting SpacyEntityExtractor with 70 samples\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models: 100%|██████████| 7/7 [07:00<00:00, 60.04s/it]\n",
      "Testing models: 100%|██████████| 7/7 [07:00<00:00, 60.04s/it]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Create predictions folder\n",
    "predictions_dir = FILES_DIR / 'predictions'\n",
    "predictions_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Test all models and collect results\n",
    "results = []\n",
    "runs = 5\n",
    "for run in range(runs):\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    train_df = train_df.sample(frac=0.3)\n",
    "    for config in tqdm(MODEL_CONFIGS, desc=\"Testing models\"):\n",
    "        model_name = config['name']\n",
    "        model_info = config['extra_info']\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Create extractor using factory function\n",
    "            extractor = create_multi_entity_extractor(config)\n",
    "            \n",
    "            # Fit and predict\n",
    "            fit_start = time.time()\n",
    "            extractor.fit(train_df['text'], train_df[['persons', 'organizations', 'locations']])\n",
    "            fit_time = time.time() - fit_start\n",
    "            \n",
    "            predict_start = time.time()\n",
    "            predictions = extractor.predict(test_df['text'])\n",
    "            predict_time = time.time() - predict_start\n",
    "            \n",
    "            total_time = time.time() - start_time\n",
    "            \n",
    "            # Save predictions to file as DataFrame with true values\n",
    "            model_size = model_info.get('model', 'N/A')\n",
    "            safe_model_size = model_size.replace('/', '_').replace('-', '_')\n",
    "            predictions_file = predictions_dir / f\"{model_name}_{safe_model_size}_predictions.csv\"\n",
    "            \n",
    "            # Create DataFrame with predictions\n",
    "            predictions_df = pd.DataFrame(predictions)\n",
    "            \n",
    "            # Add true values from test set with TRUE_ prefix\n",
    "            true_values = test_df[['persons', 'organizations', 'locations']].copy()\n",
    "            true_values.columns = ['TRUE_persons', 'TRUE_organizations', 'TRUE_locations']\n",
    "            \n",
    "            # Combine predictions and true values\n",
    "            combined_df = pd.concat([predictions_df.reset_index(), true_values.reset_index()], axis=1, ignore_index=True)\n",
    "            combined_df.to_csv(predictions_file, index=False)\n",
    "            \n",
    "            # Store results with all metadata\n",
    "            results.append({\n",
    "                'run': run,\n",
    "                'model_name': model_name,\n",
    "                **model_info,\n",
    "                'status': 'success',\n",
    "                'fit_time': fit_time,\n",
    "                'predict_time': predict_time,\n",
    "                'total_time': total_time,\n",
    "                'error': None,\n",
    "                'stats': extractor.stats,\n",
    "                'predictions_file': str(predictions_file)\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            total_time = time.time() - start_time\n",
    "            error_msg = str(e)\n",
    "            \n",
    "            results.append({\n",
    "                'run': run,\n",
    "                'model_name': model_name,\n",
    "                **model_info,\n",
    "                'status': 'error',\n",
    "                'fit_time': 0,\n",
    "                'predict_time': 0,\n",
    "                'total_time': total_time,\n",
    "                'error': error_msg,\n",
    "                'stats': {},\n",
    "                'predictions_file': None\n",
    "            })\n",
    "        \n",
    "        results_df = pd.json_normalize(results)\n",
    "        results_df.to_csv(EXPERIMENTAL_RESULTS_DIR / 'model_evaluation_results_multi_pass.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727cd89f-8706-4897-863b-044f27cd5678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Save results to CSV"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
