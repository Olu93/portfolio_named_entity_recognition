{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "510fc79d-752f-4248-8611-fc13d6f30b99",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " # Named Entity Recognition (NER) Data Conversion\n",
    "\n",
    " This notebook converts the chunked dataset into CoNLL-2003 format using LLM-based annotation. We'll use GPT-4o-mini to automatically annotate entities in the text chunks, creating a structured dataset suitable for training and evaluating NER models.\n",
    "\n",
    " ## Setup: Import required libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b79e63a-0be4-4497-9cd7-128bacabdf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "from notebook_config import DATASETS_DIR, FILES_DIR\n",
    "import pandas as pd\n",
    "import json\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261fe30c-8322-4d52-8b46-cde5813e2954",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Define Pydantic Schema for Structured Output\n",
    "\n",
    " Create Pydantic models to ensure consistent and validated output from the LLM:\n",
    "\n",
    " **TokenNERPair**: Represents individual token-tag pairs in BIO tagging format\n",
    " **Entity**: Represents extracted entities with their type and value\n",
    " **NERAnnotation**: Complete annotation structure containing original text, tokenized annotations, and entity list\n",
    "\n",
    " This structured approach ensures data consistency and enables easy validation of LLM outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eea3ac-e526-4320-a5de-de9d4e4aef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "class TokenNERPair(BaseModel):\n",
    "    token: str\n",
    "    tag: Literal[\"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"B-MISC\", \"I-MISC\", \"O\"]\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    entity_type: Literal[\"PER\", \"ORG\", \"LOC\", \"MISC\"] = Field(description=\"The type of entity person=PER, organization=ORG, location=LOC, other=MISC\")\n",
    "    entity_value: str = Field(description=\"The value of the entity\")\n",
    "\n",
    "class NERAnnotation(BaseModel):\n",
    "    original_text: str\n",
    "    tokens: List[TokenNERPair]\n",
    "    entities: list[Entity] = Field(description=\"List of entities found in the text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaf54e7-969a-477b-9064-801c91e43867",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Load Chunked Dataset\n",
    "\n",
    " Load the semantically chunked dataset created in the previous notebook. This dataset contains:\n",
    " - **Text chunks**: Optimally-sized text segments for NER annotation\n",
    " - **Entity metadata**: Pre-existing entity annotations from the original dataset\n",
    " - **Token counts**: Pre-computed token lengths for each chunk\n",
    "\n",
    " We'll use this as input for LLM-based NER annotation to create training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1c759e-205c-496e-90f5-474de14865fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 lines to process from CSV\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "input_file = DATASETS_DIR / \"semantic_split_complete_dataset.csv\"\n",
    "df = pd.read_csv(input_file).iloc[:5]\n",
    "lines = df['text'].tolist()\n",
    "print(f\"Found {len(lines)} lines to process from CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdd9149-e064-4d66-9dcf-db8aa8e2dee9",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Initialize LLM and Structured Output Parser\n",
    "\n",
    " Set up the LLM with structured output capabilities:\n",
    " - **Model**: GPT-4o-mini for cost-effective yet accurate annotation\n",
    " - **Temperature**: 0.0 for consistent, deterministic outputs\n",
    " - **Structured output**: Enforces Pydantic schema validation\n",
    "\n",
    " This ensures reliable and consistent NER annotations across all text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33918878-01f6-4860-a012-a3b12944737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.0).with_structured_output(NERAnnotation)\n",
    "# parser = PydanticOutputParser(pydantic_object=NERAnnotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612c34d5-efb5-4474-801f-9db46aaf893a",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Create Specialized NER Prompt Template\n",
    "\n",
    " Design a comprehensive prompt template that guides the LLM to produce high-quality NER annotations:\n",
    "\n",
    " **Key Features:**\n",
    " - **Entity type definitions**: Clear specifications for PER, ORG, LOC, and MISC entities\n",
    " - **BIO tagging instructions**: Standard CoNLL-2003 format with proper begin/inside/outside tags\n",
    " - **Quality constraints**: Specific rules for person names (full names only, no titles)\n",
    " - **Reference examples**: Concrete examples to guide annotation decisions\n",
    " - **Known entities**: Incorporates pre-existing entity annotations as context\n",
    "\n",
    " This prompt ensures consistent annotation quality and adherence to NER standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5175fc6-524c-4e2f-98c9-6b3169380904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "You are an expert Named Entity Recognition (NER) annotator.\n",
    "Annotate the given text in CoNLL-2003 format using BIO tagging.\n",
    "\n",
    "Entity types to identify:\n",
    "- PER: Names of people. ⚠️ ONLY include **full names** (e.g., \"Barack Obama\"). ❌ Do NOT include:\n",
    "  - First names only (e.g., \"Barack\")\n",
    "  - Last names only (e.g., \"Obama\")\n",
    "  - Initials or abbreviations (e.g., \"B. Obama\")\n",
    "  - Titles or roles (e.g., \"President\", \"Dr.\", \"CEO\")\n",
    "  - Name fragments or mentions without a clear full name\n",
    "\n",
    "- ORG: Companies, institutions, government bodies (e.g., Microsoft, United Nations, FBI)\n",
    "- LOC: Countries, cities, states, physical locations (e.g., Germany, New York, Kremlin)\n",
    "- MISC: Other named entities that don't fit the above categories\n",
    "\n",
    "BIO tagging:\n",
    "Use standard CoNLL-2003 tags:\n",
    "B-PER, I-PER, B-ORG, I-ORG, B-LOC, I-LOC, B-MISC, I-MISC, O\n",
    "\n",
    "Reference examples:\n",
    "PERSONS: Joe Biden, Angela Merkel, Elon Musk\n",
    "ORGANIZATIONS: Google, NATO, European Commission\n",
    "LOCATIONS: Paris, Brazil, Mount Everest\n",
    "\n",
    "Known entities in this text:\n",
    "- PERSONS: {persons}\n",
    "- ORGANIZATIONS: {organizations}\n",
    "- LOCATIONS: {locations}\n",
    "\n",
    "Now annotate the text accordingly.\n",
    "\n",
    "Text to annotate: {text}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16d75e6-27ce-4ee2-a8fd-ceec883ea59d",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Create Processing Chain\n",
    "\n",
    " Combine the prompt template with the LLM to create a processing chain that:\n",
    " - Takes text input and entity context\n",
    " - Applies the NER annotation prompt\n",
    " - Returns structured output conforming to our Pydantic schema\n",
    "\n",
    " This chain ensures consistent processing across all text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2325a739-4ea1-4225-bb3a-f1c31984e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "chain = prompt_template | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ec7a18-cb76-4d73-aca5-452e8ba3205f",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Initialize Output Files and Processing Loop\n",
    "\n",
    " Set up output files for both CoNLL format and JSON format:\n",
    " - **CoNLL file**: Standard format for NER model training and evaluation\n",
    " - **JSON file**: Rich format preserving full annotation details and metadata\n",
    "\n",
    " Initialize empty files to prepare for incremental writing during processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ecc7ce-6d98-4ed4-a382-8cd1838c8a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "results = []\n",
    "output_file = FILES_DIR / \"ner_annotations_3.conll\"\n",
    "json_file = FILES_DIR / \"ner_annotations_3.json\"\n",
    "with open(output_file, 'w', encoding='utf-8'): pass  # Empty file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2a5ae0-dfb7-4700-9d46-5c45229dd739",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Process Text Chunks with LLM Annotation\n",
    "\n",
    " Iterate through each text chunk and apply LLM-based NER annotation:\n",
    "\n",
    " **Processing Steps:**\n",
    " 1. **Input preparation**: Extract text and entity context from each row\n",
    " 2. **LLM annotation**: Apply the NER chain to generate structured annotations\n",
    " 3. **Output formatting**: Convert to both CoNLL and JSON formats\n",
    " 4. **Incremental saving**: Write results after each chunk to prevent data loss\n",
    " 5. **Error handling**: Capture and log any processing errors\n",
    "\n",
    " This approach ensures robust processing of large datasets with progress tracking and error recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0d54be-846e-45f0-b922-22bbed1db7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-07-29 16:42:03] INFO in _client: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  20%|██        | 1/5 [01:02<04:09, 62.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-07-29 16:42:20] INFO in _client: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  40%|████      | 2/5 [01:19<01:46, 35.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-07-29 16:42:55] INFO in _client: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  60%|██████    | 3/5 [01:53<01:10, 35.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-07-29 16:43:06] INFO in _client: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  80%|████████  | 4/5 [02:04<00:25, 25.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-07-29 16:43:19] INFO in _client: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles: 100%|██████████| 5/5 [02:17<00:00, 27.57s/it]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "for i, (line, row) in enumerate(tqdm(zip(lines, df.itertuples()), desc=\"Processing articles\", total=len(lines))):\n",
    "    try:\n",
    "        # Prepare input for single article\n",
    "        input_dict = {\n",
    "            \"text\": line,\n",
    "            \"persons\": getattr(row, 'persons', ''),\n",
    "            \"organizations\": getattr(row, 'organizations', ''),\n",
    "            \"locations\": getattr(row, 'locations', ''),\n",
    "            # \"format_instructions\": parser.get_format_instructions()\n",
    "        }\n",
    "        \n",
    "        # Process single article\n",
    "        parsed_result = chain.invoke(input_dict)\n",
    "        \n",
    "        if parsed_result:\n",
    "            # Process the chunk directly\n",
    "            tokens_and_tags = [(t.token, t.tag) for t in parsed_result.tokens]\n",
    "            all_entities = [e.model_dump(mode=\"python\") for e in parsed_result.entities]\n",
    "\n",
    "            result = {\n",
    "                \"original_text\": line,\n",
    "                \"conll_annotations\": tokens_and_tags,\n",
    "                \"entities\": all_entities\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(\"Empty or malformed result\")\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "        # Write to CoNLL file\n",
    "        with open(output_file, 'a', encoding='utf-8') as f:\n",
    "            for token, tag in tokens_and_tags:\n",
    "                f.write(f\"{token} {tag}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "        # Save JSON after each article (incremental saving)\n",
    "        with open(json_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing article {i}: {str(e)}\")\n",
    "        results.append({\n",
    "            \"original_text\": line,\n",
    "            \"conll_annotations\": [],\n",
    "            \"entities\": [],\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "        \n",
    "        # Save error results to JSON\n",
    "        with open(json_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696361b5-4cb7-41d7-9d67-86ff00b7ba5a",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Processing Summary and Statistics\n",
    "\n",
    " Generate comprehensive statistics about the annotation process:\n",
    "\n",
    " **Key Metrics:**\n",
    " - **Total processed**: Number of chunks successfully annotated\n",
    " - **Total tokens**: Overall token count across all annotations\n",
    " - **Tag distribution**: Frequency of each entity type and BIO tag\n",
    " - **Error analysis**: Any processing failures and their causes\n",
    "\n",
    " These statistics help validate annotation quality and identify potential issues in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b18c563-677f-497e-85f4-6e1ec0751aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CoNLL saved to c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\ner_annotations_3.conll\n",
      "✅ JSON saved to c:\\Users\\User\\Workspace\\work_practice\\interview\\toptal\\take-home-assignment\\files\\ner_annotations_3.json\n",
      "Total processed: 5\n",
      "Total tokens processed: 549\n",
      "Tags by type:\n",
      "  B-LOC: 6\n",
      "  B-MISC: 5\n",
      "  B-ORG: 12\n",
      "  B-PER: 2\n",
      "  I-LOC: 3\n",
      "  I-ORG: 16\n",
      "  I-PER: 2\n",
      "  O: 503\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "print(f\"\\n✅ CoNLL saved to {output_file}\")\n",
    "print(f\"✅ JSON saved to {json_file}\")\n",
    "print(f\"Total processed: {len(results)}\")\n",
    "\n",
    "total_tokens = sum(len(r[\"conll_annotations\"]) for r in results if \"error\" not in r)\n",
    "print(f\"Total tokens processed: {total_tokens}\")\n",
    "\n",
    "tag_counts = {}\n",
    "for result in results:\n",
    "    if \"error\" not in result:\n",
    "        for _, tag in result[\"conll_annotations\"]:\n",
    "            tag_counts[tag] = tag_counts.get(tag, 0) + 1\n",
    "\n",
    "print(\"Tags by type:\")\n",
    "for tag, count in sorted(tag_counts.items()):\n",
    "    print(f\"  {tag}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b67867e-63a4-41bc-ad6f-90bcd7942489",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Sample Annotation Review\n",
    "\n",
    " Display sample annotations to validate the quality and format of the generated NER data:\n",
    "\n",
    " **Review Elements:**\n",
    " - **Original text**: Source content being annotated\n",
    " - **CoNLL format**: Token-tag pairs in standard format\n",
    " - **Entity extraction**: Structured entity information\n",
    "\n",
    " This review helps ensure the annotation quality meets expectations for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa44e4e-f365-4927-857f-7e9cea0e3de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example annotations:\n",
      "\n",
      "1. Text: A drug is available for monkeypox patients who have or who are at risk of severe disease, but doctor...\n",
      "   CoNLL:\n",
      "     A O\n",
      "     drug O\n",
      "     is O\n",
      "     available O\n",
      "     for O\n",
      "     monkeypox O\n",
      "     patients O\n",
      "     who O\n",
      "     have O\n",
      "     or O\n",
      "     ...\n",
      "\n",
      "2. Text: However, doctors across the country suggest that significant barriers remain, causing some patients ...\n",
      "   CoNLL:\n",
      "     However O\n",
      "     , O\n",
      "     doctors O\n",
      "     across O\n",
      "     the O\n",
      "     country O\n",
      "     suggest O\n",
      "     that O\n",
      "     significant O\n",
      "     barriers O\n",
      "     ...\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "print(\"\\nExample annotations:\")\n",
    "for i, r in enumerate(results[:2]):\n",
    "    if \"error\" not in r:\n",
    "        print(f\"\\n{i+1}. Text: {r['original_text'][:100]}...\")\n",
    "        print(\"   CoNLL:\")\n",
    "        for token, tag in r[\"conll_annotations\"][:10]:\n",
    "            print(f\"     {token} {tag}\")\n",
    "        if len(r[\"conll_annotations\"]) > 10:\n",
    "            print(\"     ...\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
